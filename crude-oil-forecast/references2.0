@book{Chatfield2000,
   author = {C Chatfield},
   publisher = {Chapman and Hall/CRC Boca Raton, FL},
   title = {Time-series forecasting},
   year = {2000},
}
@article{Decan2023,
   author = {A Decan and T Mens and H O Delicheh},
   journal = {Journal of Systems and Software},
   pages = {111827},
   publisher = {Elsevier},
   title = {On the outdatedness of workflows in the GitHub Actions ecosystem},
   volume = {206},
   year = {2023},
}
@article{Akaike1974,
   author = {H Akaike},
   issue = {6},
   journal = {IEEE transactions on automatic control},
   pages = {716-723},
   publisher = {IEEE},
   title = {A new look at the statistical model identification},
   volume = {19},
   year = {1974},
}
@article{Lindsey1999,
   author = {J K Lindsey},
   issue = {4},
   journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
   pages = {553-561},
   publisher = {Wiley Online Library},
   title = {On the use of corrections for overdispersion},
   volume = {48},
   year = {1999},
}
@article{Cheung1997,
   author = {Y W Cheung and K S Lai},
   issue = {5},
   journal = {Econometric Theory},
   pages = {679-691},
   publisher = {Cambridge University Press},
   title = {Bandwidth selection, prewhitening, and the power of the Phillips-Perron test},
   volume = {13},
   year = {1997},
}
@article{Hobijn2004,
   author = {B Hobijn and P H Franses and M Ooms},
   issue = {4},
   journal = {Statistica Neerlandica},
   pages = {483-502},
   publisher = {Springer},
   title = {Generalizations of the KPSS-test for stationarity},
   volume = {58},
   year = {2004},
}
@article{Mushtaq2011,
   author = {R Mushtaq},
   journal = {International Research Journal of Finance and Economics},
   title = {Augmented dickey fuller test},
   volume = {88},
   year = {2011},
}
@article{Daneshvar2022,
   author = {A Daneshvar and M Ebrahimi and F Salahi and M Rahmaty and M Homayounfar},
   issue = {1},
   journal = {Computational Intelligence and Neuroscience},
   pages = {6140796},
   publisher = {Hindawi},
   title = {Brent crude oil price forecast utilizing deep neural network architectures},
   volume = {2022},
   year = {2022},
}
@article{Hamilton1994,
   author = {J D Hamilton and R Susmel},
   issue = {1-2},
   journal = {Journal of econometrics},
   pages = {307-333},
   publisher = {Elsevier},
   title = {Autoregressive conditional heteroskedasticity and changes in regime},
   volume = {64},
   year = {1994},
}
@inproceedings{Samal2019,
   author = {K K R Samal and K S Babu and S K Das and A Acharaya},
   journal = {Proceedings of the 2019 international conference on information technology and computer communications},
   pages = {80-85},
   title = {Time series based air pollution forecasting using SARIMA and prophet model},
   year = {2019},
}
@book{Golyandina2001,
   author = {N Golyandina and V Nekrutkin and A A Zhigljavsky},
   publisher = {CRC press},
   title = {Analysis of time series structure: SSA and related techniques},
   year = {2001},
}
@inproceedings{Aziz2021,
   author = {M I A Aziz and M H Barawi},
   journal = {AES 2021},
   pages = {253-263},
   title = {FORECASTING CRUDE OIL PRICE USING ARIMA AND FACEBOOK PROPHET WITHI MACHINE LEARNING},
   year = {2021},
}
@article{Chinn2005,
   author = {M D Chinn and M LeBlanc and O Coibion},
   title = {The predictive content of energy futures: an update on petroleum, natural gas, heating oil and gasoline},
   year = {2005},
}
@article{Soyiri2012,
   author = {I N Soyiri and D D Reidpath},
   journal = {International journal of general medicine},
   pages = {381-390},
   publisher = { Dove Medical Press Ltd},
   title = {Evolving forecasting classifications and applications in health forecasting},
   volume = {5},
   year = {2012},
}
@article{Hassani2010,
   author = {H Hassani},
   journal = {Optimal decisions in statistics and data analysis},
   pages = {1-10},
   title = {A brief introduction to singular spectrum analysis},
   year = {2010},
}
@article{,
   author = {D Güleryüz and E Özden},
   issue = {20},
   journal = {Avrupa Bilim ve Teknoloji Dergisi},
   pages = {1-9},
   title = {The prediction of Brent crude oil trend using LSTM and Facebook prophet},
   year = {2020},
}
@article{Hassani2010,
   author = {H Hassani and D Thomakos},
   issue = {3},
   journal = {Statistics and its Interface},
   pages = {377-397},
   publisher = {IOS Press},
   title = {A review on singular spectrum analysis for economic and financial time series},
   volume = {3},
   year = {2010},
}
@article{Hassani2007,
   author = {H Hassani},
   issue = {07},
   journal = {International Journal of Bifurcation and Chaos},
   pages = {2345-2374},
   publisher = {World Scientific},
   title = {Singular spectrum analysis: methodology and comparison},
   volume = {17},
   year = {2007},
}
@article{Zhigljavsky2010,
   author = {A Zhigljavsky},
   issue = {3},
   journal = {Statistics and its Interface},
   pages = {255-258},
   publisher = {IOS Press},
   title = {Singular spectrum analysis for time series: Introduction to this special issue},
   volume = {3},
   year = {2010},
}
@article{Fraedrich1986,
   author = {K Fraedrich},
   issue = {5},
   journal = {Journal of atmospheric sciences},
   pages = {419-432},
   title = {Estimating the dimensions of weather and climate attractors},
   volume = {43},
   year = {1986},
}
@article{Broomhead1986,
   author = {D S Broomhead and G P King},
   issue = {2-3},
   journal = {Physica D: Nonlinear Phenomena},
   pages = {217-236},
   publisher = {Elsevier},
   title = {Extracting qualitative dynamics from experimental data},
   volume = {20},
   year = {1986},
}
@article{Colebrook1978,
   author = {J M Colebrook},
   issue = {1},
   journal = {Oceanologica acta},
   pages = {9-23},
   publisher = {Elsevier},
   title = {Continuous plankton records-zooplankton and environment, northeast Atlantic and North-Sea, 1948-1975},
   volume = {1},
   year = {1978},
}
@article{Vautard1992,
   author = {R Vautard and P Yiou and M Ghil},
   issue = {1-4},
   journal = {Physica D: Nonlinear Phenomena},
   pages = {95-126},
   publisher = {Elsevier},
   title = {Singular-spectrum analysis: A toolkit for short, noisy chaotic signals},
   volume = {58},
   year = {1992},
}
@article{Pike1984,
   author = {E R Pike and J G McWhirter and M Bertero and C De Mol},
   issue = {6},
   journal = {IEE Proceedings F (Communications, Radar and Signal Processing)},
   pages = {660-667},
   title = {Generalised information theory for inverse problems in signal processing},
   volume = {131},
   year = {1984},
}
@article{Kumaresan1980,
   author = {R Kumaresan and D W Tufts},
   issue = {6},
   journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
   pages = {949-954},
   publisher = {IEEE},
   title = {Data-adaptive principal component signal processing},
   volume = {28},
   year = {1980},
}
@inbook{,
   author = {S Garc\'\ia and J Luengo and F Herrera},
   journal = {Data preprocessing in data mining},
   pages = {59-139},
   publisher = {Springer},
   title = {Data preprocessing in data mining},
   volume = {72},
   year = {2015},
}
@article{,
   author = {S Garc\'\ia and S Ram\'\irez-Gallego and J Luengo and J M Ben\'\itez and F Herrera},
   journal = {Big Data Analytics},
   pages = {1-18},
   publisher = {Elsevier},
   title = {Big data preprocessing: methods and prospects},
   volume = {1},
   year = {2016},
}
@article{Guliyev2022,
   author = {H Guliyev and E Mustafayev},
   journal = {Resources Policy},
   pages = {102664},
   publisher = {Elsevier},
   title = {Predicting the changes in the WTI crude oil price dynamics using machine learning models},
   volume = {77},
   year = {2022},
}
@book{Box2015,
   author = {G E Box and G M Jenkins and G C Reinsel and G M Ljung},
   publisher = {John Wiley & Sons},
   title = {Time series analysis: Forecasting and control},
   year = {2015},
}
@book{Cryer2008,
   author = {J D Cryer and K S Chan},
   publisher = {Oxford University Press New York},
   title = {Time series analysis: with applications in R},
   year = {2008},
}
@article{Kane2014,
   author = {M J Kane and N Price and M Scotch and P Rabinowitz},
   issue = {1},
   journal = {BMC bioinformatics},
   pages = {1-9},
   publisher = {BioMed Central},
   title = {Comparison of ARIMA and random forest time series models for prediction of avian influenza H5N1 outbreaks},
   volume = {15},
   year = {2014},
}
@inproceedings{Cootes2012,
   author = {T F Cootes and M C Ionita and C Lindner and P Sauer},
   journal = {Computer Vision–ECCV 2012},
   pages = {278-291},
   title = {Robust and accurate shape model fitting using random forest regression voting},
   year = {2012},
}
@article{Breiman2001,
   author = {L Breiman},
   issue = {1},
   journal = {Machine learning},
   pages = {5-32},
   publisher = {Springer},
   title = {Random forests},
   volume = {45},
   year = {2001},
}
@article{Aamir2018,
   author = {M Aamir and A Shabri and M Ishaq},
   issue = {4},
   journal = {Malaysian Journal of Fundamental and Applied Sciences},
   pages = {471-483},
   title = {Improving forecasting accuracy of crude oil prices using decomposition ensemble model with reconstruction of IMFs based on ARIMA model},
   volume = {14},
   year = {2018},
}
@article{Ruiz2016,
   author = {L G B Ruiz and M P Cuéllar and M D Calvo-Flores and MDCP Jiménez},
   issue = {9},
   journal = {Energies},
   pages = {684},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {An application of non-linear autoregressive neural networks to predict energy consumption in public buildings},
   volume = {9},
   year = {2016},
}
@article{Noureen2019,
   author = {S Noureen and S Atique and V Roy and S Bayne},
   issue = {09},
   journal = {International Research Journal of Engineering and Technology},
   pages = {1812-1821},
   title = {A comparative forecasting analysis of ARIMA model vs random forest algorithm for a case study of small-scale industrial load},
   volume = {6},
   year = {2019},
}
@article{Ahmed2014,
   author = {R A Ahmed and A B Shabri},
   issue = {3},
   journal = {American Journal of Applied Sciences},
   pages = {425},
   publisher = {Science Publications},
   title = {Daily crude oil price forecasting model using ARIMA, generalized autoregressive conditional heteroscedastic and support vector machines},
   volume = {11},
   year = {2014},
}
@article{Wang2005,
   author = {S Y Wang and L A Yu and K K Lai},
   issue = {2},
   journal = {Journal of Systems Science and Complexity},
   pages = {145-166},
   publisher = {World Scientific},
   title = {Crude oil price forecasting with TEI@I methodology},
   volume = {18},
   year = {2005},
}
@article{Mensah2015,
   author = {E K Mensah},
   issue = {2},
   journal = {International Journal of Energy Economics and Policy},
   pages = {224-230},
   title = {Box-Jenkins modelling and forecasting of Brent crude oil price},
   volume = {5},
   year = {2015},
}
@article{Petukhova2018,
   author = {T Petukhova and D Ojkic and B McEwen and R Deardon and Z Poljak},
   issue = {6},
   journal = {PloS one},
   pages = {e0198313},
   publisher = {Public Library of Science San Francisco, CA USA},
   title = {Assessment of autoregressive integrated moving average (ARIMA), generalized linear autoregressive moving average (GLARMA), and random forest (RF) time series regression models for predicting influenza A virus frequency in swine in Ontario, Canada},
   volume = {13},
   year = {2018},
}
@article{Chen2019,
   author = {E Chen and X J He},
   issue = {4},
   journal = {Journal of International Technology and Information Management},
   pages = {2-16},
   title = {Crude oil price prediction with decision tree based regression approach},
   volume = {27},
   year = {2019},
}
@inproceedings{Nwulu2017,
   author = {N I Nwulu},
   journal = {2017 International Artificial Intelligence and Data Processing Symposium (IDAP)},
   pages = {1-5},
   title = {A decision trees approach to oil price prediction},
   year = {2017},
}
@article{Cantah2015,
   author = {W G Cantah and E E Asmah},
   issue = {5},
   journal = {International Journal of Economics, Commerce and Management},
   title = {Crude oil price and growth of output: the case of Ghana},
   volume = {3},
   year = {2015},
}
@article{Armah2003,
   author = {B Armah},
   journal = {Energy Commission of Ghana publication, Accra},
   title = {Economic analysis of the energy sector},
   year = {2003},
}
@article{Lee2006,
   author = {J Lee and J A List and M C Strazicich},
   issue = {3},
   journal = {Journal of Environmental Economics and Management},
   pages = {354-370},
   publisher = {Elsevier},
   title = {Non-renewable resource prices: Deterministic or stochastic trends?},
   volume = {51},
   year = {2006},
}
@article{Charles2014,
   author = {A Charles and O Darné},
   journal = {Energy Policy},
   pages = {729-742},
   publisher = {Elsevier},
   title = {Volatility persistence in crude oil markets},
   volume = {65},
   year = {2014},
}
@article{Eshun2016,
   author = {M E Eshun and J Amoako-Tuffour},
   issue = {6},
   journal = {Energy, Sustainability and Society},
   pages = {1-9},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {A review of the trends in Ghana’s power sector},
   volume = {1},
   year = {2016},
}
@misc{,
   author = {US-Energy Information Administration},
   publisher = {IndexMundi},
   title = {Ghana Crude Oil Production and Consumption by Year},
   year = {2014},
}
@book{,
   author = {of Ghana},
   publisher = {Strategic Planning Division, Energy Commission of Ghana, Accra, Ghana},
   title = {National Energy Statistics 2006–2015},
   year = {2016},
}
@book{,
   author = {of Ghana},
   publisher = {Strategic Planning Division, Energy Commission of Ghana, Accra, Ghana},
   title = {National Energy Statistics 2000–2013},
   year = {2014},
}
@article{Evgenidis2018,
   author = {A Evgenidis},
   journal = {Finance Research Letters},
   pages = {150-155},
   publisher = {Elsevier},
   title = {Do all oil price shocks have the same impact? Evidence from the euro area},
   volume = {26},
   year = {2018},
}
@article{Zhang2013,
   author = {Y J Zhang and Z Y Wang},
   journal = {Applied Energy},
   pages = {220-228},
   publisher = {Elsevier},
   title = {Investigating the price discovery and risk transfer functions in the crude oil and gasoline futures markets: Some empirical evidence},
   volume = {104},
   year = {2013},
}
@article{Zhang2015,
   author = {J L Zhang and Y J Zhang and L Zhang},
   journal = {Energy Economics},
   pages = {649-659},
   publisher = {Elsevier},
   title = {A novel hybrid method for crude oil price forecasting},
   volume = {49},
   year = {2015},
}
@article{Wang2021,
   author = {W Wang and L Wei},
   issue = {1},
   journal = {Agricultural Economics},
   pages = {3-17},
   publisher = {Wiley Online Library},
   title = {Impacts of agricultural price support policy on price variability and welfare: Evidence from China’s soybean market},
   volume = {52},
   year = {2021},
}
@article{Ocran2007,
   author = {M K Ocran},
   journal = {AERC Research Paper},
   title = {A modelling of Ghana’s inflation experience: 1960–2003},
   volume = {169},
   year = {2007},
}
@book{,
   author = {Centre for Policy Analysis},
   publisher = {Centre for Policy Analysis, Accra},
   title = {The state of the Ghanaian economy 2002–2003},
   year = {2003},
}
@book{Hutchful2002,
   author = {E Hutchful},
   publisher = {James Currey, London},
   title = {Ghana's adjustment experience, the paradox of reform},
   year = {2002},
}
@inbook{Fosu2008,
   author = {A K Fosu and E Aryeetey},
   journal = {The economy of Ghana},
   pages = {36-77},
   publisher = {Woeli Publishing Services, Accra},
   title = {Ghana’s post-independence economic growth, 1960–2000},
   year = {2008},
}
@article{Engle1982,
   author = {R F Engle},
   issue = {4},
   journal = {Econometrica: Journal of the Econometric Society},
   pages = {987-1007},
   publisher = {JSTOR},
   title = {Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation},
   volume = {50},
   year = {1982},
}
@article{Guo2012,
   author = {X Guo and D Li and A Zhang},
   journal = {AASRI Procedia},
   pages = {525-530},
   publisher = {The African Academy of Sciences},
   title = {Improved support vector machine oil price forecast model based on genetic algorithm optimization parameters},
   volume = {1},
   year = {2012},
}
@inproceedings{Xie2006,
   author = {W Xie and L Yu and S Xu and S Wang},
   journal = {Computational Science–ICCS 2006},
   pages = {444-451},
   title = {A new method for crude oil price forecasting based on support vector machines},
   year = {2006},
}
@article{Gileva2010,
   author = {T Gileva},
   journal = {Université Paris 1},
   title = {Econometrics of crude oil markets},
   year = {2010},
}
@article{Narayan2007,
   author = {P K Narayan and S Narayan},
   issue = {12},
   journal = {Energy Policy},
   pages = {6549-6553},
   publisher = {Elsevier},
   title = {Modelling oil price volatility},
   volume = {35},
   year = {2007},
}
@article{Morales2014,
   author = {L Morales and B Andreosso-O’Callaghan},
   journal = {Journal of Economics and Finance},
   pages = {492-517},
   publisher = {Wiley Online Library},
   title = {Volatility analysis of precious metals returns and oil returns: An ICSS approach},
   volume = {38},
   year = {2014},
}
@article{Sadorsky2006,
   author = {P Sadorsky},
   issue = {4},
   journal = {Energy Economics},
   pages = {467-488},
   publisher = {Elsevier},
   title = {Modeling and forecasting petroleum futures volatility},
   volume = {28},
   year = {2006},
}
@misc{Filonov2016,
   author = {P Filonov and A Lavrentyev and A Vorontsov},
   institution = {arXiv preprint arXiv:1612.06676},
   title = {Multivariate industrial time series with cyber-attack simulation: Fault detection using an lstm-based predictive data model},
   year = {2016},
}
@article{Salisu2013,
   author = {A A Salisu and I O Fasanya},
   journal = {Energy Policy},
   pages = {554-562},
   publisher = {Elsevier},
   title = {Modelling oil price volatility with structural breaks},
   volume = {52},
   year = {2013},
}
@article{Robe2016,
   author = {M A Robe and J Wallen},
   issue = {4},
   journal = {Journal of Futures Markets},
   pages = {317-344},
   publisher = {Taylor & Francis},
   title = {Fundamentals, derivatives market information and oil price volatility},
   volume = {36},
   year = {2016},
}
@misc{Hamilton2014,
   author = {J D Hamilton},
   institution = {National Bureau of Economic Research},
   title = {The changing face of world oil markets},
   year = {2014},
}
@article{Jin2018,
   author = {C Jin and W Yao and Y Gao and B Hou},
   journal = {Energy Economics},
   pages = {582-592},
   publisher = {Elsevier},
   title = {Analysis on the volatility spillovers in global crude oil market: A new evidence from SVARMA model},
   volume = {74},
   year = {2018},
}
@article{Oberndorfer2009,
   author = {U Oberndorfer},
   issue = {12},
   journal = {Energy Policy},
   pages = {5787-5795},
   publisher = {Elsevier},
   title = {Energy prices, volatility, and the stock market: Evidence from the Eurozone},
   volume = {37},
   year = {2009},
}
@article{Quartey2016,
   author = {P Quartey},
   issue = {14},
   journal = {Ghana Strategy Support Program (GSSP) Background Paper Series},
   title = {Exchange rate movements and the Ghanaian economy},
   year = {2016},
}
@article{Boamah2017,
   author = {N A Boamah and H Olufunmilayo and J Du and E Asare},
   issue = {5},
   journal = {International Journal of Energy Economics and Policy},
   pages = {130-139},
   title = {The impact of oil price on economic growth: Evidence from Ghana},
   volume = {7},
   year = {2017},
}
@article{Aryeetey2016,
   author = {E Aryeetey and G Mohan and R Osei and P Quartey},
   issue = {21},
   journal = {Ghana Strategy Support Program (GSSP) Background Paper Series},
   title = {Oil prices and the Ghanaian economy},
   year = {2016},
}
@article{Asare2018,
   author = {E Asare and G Tweneboah},
   issue = {1},
   journal = {Cogent Economics & Finance},
   pages = {1534410},
   publisher = {Taylor & Francis},
   title = {The impact of crude oil prices on economic growth: A case study of Ghana},
   volume = {6},
   year = {2018},
}
@article{Owusu2019,
   author = {E B Owusu and J Du},
   issue = {3},
   journal = {Journal of Energy Research and Reviews},
   pages = {54-69},
   title = {Determinants of crude oil prices in the Ghanaian economy: A cointegration analysis},
   volume = {4},
   year = {2019},
}
@article{Wang2020,
   author = {Y Wang and C Wu},
   journal = {Energy Reports},
   pages = {868-883},
   publisher = {Elsevier},
   title = {A review of crude oil price forecasting techniques},
   volume = {6},
   year = {2020},
}
@article{Yu2019,
   author = {L Yu and Y Zhao and L Tang and Z Yang},
   issue = {1},
   journal = {International Journal of Forecasting},
   pages = {213-223},
   publisher = {Elsevier},
   title = {Online big data-driven oil consumption forecasting with Google trends},
   volume = {35},
   year = {2019},
}
@article{Yu2008,
   author = {L Yu and S Wang and K K Lai},
   issue = {5},
   journal = {Energy Economics},
   pages = {2623-2635},
   publisher = {Elsevier},
   title = {Forecasting crude oil price with an EMD-based neural network ensemble learning paradigm},
   volume = {30},
   year = {2008},
}
@article{Zhang2018,
   author = {D Zhang and G Zang and J Li and K Ma and H Liu},
   journal = {Computers and Electronics in Agriculture},
   pages = {10-17},
   publisher = {Elsevier},
   title = {Prediction of soybean price in China using QR-RBF neural network model},
   volume = {154},
   year = {2018},
}
@article{Czech2021,
   author = {K Czech and I Niftiyev},
   issue = {9},
   journal = {Journal of Risk and Financial Management},
   pages = {431},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {The impact of oil price shocks on oil-dependent countries' currencies: the case of Azerbaijan and Kazakhstan},
   volume = {14},
   year = {2021},
}
@misc{,
   title = {Modelling and Forecasting Brent Crude Oil with Auto Regressive Integrated Moving Average (ARIMA)},
}
@misc{,
   title = {Modelling and Forecasting Brent Crude Oil with Random Forest Regressor},
}
@misc{Hassani2007,
   abstract = {In recent years Singular Spectrum Analysis (SSA), used as a powerful technique in time series analysis, has been developed and applied to many practical problems. In this paper, the performance of the SSA technique has been considered by applying it to a well-known time series data set, namely, monthly accidental deaths in the USA. The results are compared with those obtained using Box-Jenkins SARIMA models, the ARAR algorithm and the Holt-Winter algorithm (as described in Brockwell and Davis (2002)). The results show that the SSA technique gives a much more accurate forecast than the other methods indicated above.},
   author = {Hossein Hassani},
   journal = {Journal of Data Science},
   keywords = {ARAR algorithm,Box-Jenkins SARIMA models,Holt-Winter algorithm,USA monthly accidental deaths series,singular spectrum analysis (SSA)},
   pages = {239-257},
   title = {Singular Spectrum Analysis: Methodology and Comparison},
   volume = {5},
   year = {2007},
}
@misc{Zhigljavsky2010,
   abstract = {In this introduction we briefly describe the methodology of the Singular Spectrum Analysis (SSA), some versions and extensions of the basic version of SSA as well as connections between SSA and subspace-based methods in signal processing. We also briefly touch upon some history of SSA and mention some areas of application of SSA.},
   author = {Anatoly Zhigljavsky},
   journal = {Statistics and Its Interface},
   keywords = {60G35,62M20,Singular Spectrum Analysis,Subspace-based methods,Time series analysis},
   pages = {255-258},
   title = {Singular Spectrum Analysis for time series: Introduction to this special issue},
   volume = {3},
   url = {http://www.gistatgroup.com/gus/autossa2.pdf.},
   year = {2010},
}
@article{Alexandrov2008,
   abstract = {The paper presents a new method of trend extraction in the framework of the Singular Spectrum Analysis (SSA) approach. This method is easy to use, does not need specification of models of time series and trend, allows to extract trend in the presence of noise and oscillations and has only two parameters (besides basic SSA parameter called window length). One parameter manages scale of the extracted trend and another is a method specific threshold value. We propose procedures for the choice of the parameters. The presented method is evaluated on a simulated time series with a polynomial trend and an oscillating component with unknown period and on the seasonally adjusted monthly data of unemployment level in Alaska for the period 1976/01-2006/09.},
   author = {Theodore Alexandrov},
   month = {4},
   title = {A Method of Trend Extraction Using Singular Spectrum Analysis},
   url = {http://arxiv.org/abs/0804.3367},
   year = {2008},
}
@misc{Hassani2007,
   abstract = {In recent years Singular Spectrum Analysis (SSA), used as a powerful technique in time series analysis, has been developed and applied to many practical problems. In this paper, the performance of the SSA technique has been considered by applying it to a well-known time series data set, namely, monthly accidental deaths in the USA. The results are compared with those obtained using Box-Jenkins SARIMA models, the ARAR algorithm and the Holt-Winter algorithm (as described in Brockwell and Davis (2002)). The results show that the SSA technique gives a much more accurate forecast than the other methods indicated above.},
   author = {Hossein Hassani},
   journal = {Journal of Data Science},
   keywords = {ARAR algorithm,Box-Jenkins SARIMA models,Holt-Winter algorithm,USA monthly accidental deaths series,singular spectrum analysis (SSA)},
   pages = {239-257},
   title = {Munich Personal RePEc Archive Singular Spectrum Analysis: Methodology and Comparison Singular Spectrum Analysis: Methodology and Comparison},
   volume = {4991},
   year = {2007},
}
@inproceedings{Huang2022,
   abstract = {Self-supervised pre-training techniques have achieved remarkable progress in Document AI. Most multimodal pre-trained models use a masked language modeling objective to learn bidirectional representations on the text modality, but they differ in pre-training objectives for the image modality. This discrepancy adds difficulty to multimodal representation learning. In this paper, we propose LayoutLMv3 to pre-train multimodal Transformers for Document AI with unified text and image masking. Additionally, LayoutLMv3 is pre-trained with a word-patch alignment objective to learn cross-modal alignment by predicting whether the corresponding image patch of a text word is masked. The simple unified architecture and training objectives make LayoutLMv3 a general-purpose pre-trained model for both text-centric and image-centric Document AI tasks. Experimental results show that LayoutLMv3 achieves state-of-the-art performance not only in text-centric tasks, including form understanding, receipt understanding, and document visual question answering, but also in image-centric tasks such as document image classification and document layout analysis. The code and models are publicly available at https://aka.ms/layoutlmv3.},
   author = {Yupan Huang and Tengchao Lv and Lei Cui and Yutong Lu and Furu Wei},
   doi = {10.1145/3503161.3548112},
   isbn = {9781450392037},
   journal = {MM 2022 - Proceedings of the 30th ACM International Conference on Multimedia},
   keywords = {LayoutLM,document AI,multimodal pre-training,vision-and-language},
   month = {10},
   pages = {4083-4091},
   publisher = {Association for Computing Machinery, Inc},
   title = {LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking},
   year = {2022},
}
@misc{Zhigljavsky2010,
   abstract = {In this introduction we briefly describe the methodology of the Singular Spectrum Analysis (SSA), some versions and extensions of the basic version of SSA as well as connections between SSA and subspace-based methods in signal processing. We also briefly touch upon some history of SSA and mention some areas of application of SSA.},
   author = {Anatoly Zhigljavsky},
   journal = {Statistics and Its Interface},
   keywords = {60G35,62M20,Singular Spectrum Analysis,Subspace-based methods,Time series analysis},
   pages = {255-258},
   title = {Singular Spectrum Analysis for time series: Introduction to this special issue},
   volume = {3},
   url = {http://www.gistatgroup.com/gus/autossa2.pdf.},
   year = {2010},
}
@article{Golyandina2012,
   abstract = {Singular Spectrum Analysis (SSA) as a tool for analysis and forecasting of time series is considered. The main features of the Rssa package, which implements the SSA algorithms and methodology in R, are described and examples of its use are presented. Analysis, forecasting and parameter estimation are demonstrated by means of case study with an accompanying code in R.},
   author = {Nina Golyandina and Anton Korobeynikov},
   doi = {10.1016/j.csda.2013.04.009},
   month = {6},
   title = {Basic Singular Spectrum Analysis and Forecasting with R},
   url = {http://arxiv.org/abs/1206.6910 http://dx.doi.org/10.1016/j.csda.2013.04.009},
   year = {2012},
}
@article{Alexandrov2008,
   abstract = {The paper presents a new method of trend extraction in the framework of the Singular Spectrum Analysis (SSA) approach. This method is easy to use, does not need specification of models of time series and trend, allows to extract trend in the presence of noise and oscillations and has only two parameters (besides basic SSA parameter called window length). One parameter manages scale of the extracted trend and another is a method specific threshold value. We propose procedures for the choice of the parameters. The presented method is evaluated on a simulated time series with a polynomial trend and an oscillating component with unknown period and on the seasonally adjusted monthly data of unemployment level in Alaska for the period 1976/01-2006/09.},
   author = {Theodore Alexandrov},
   month = {4},
   title = {A Method of Trend Extraction Using Singular Spectrum Analysis},
   url = {http://arxiv.org/abs/0804.3367},
   year = {2008},
}
@misc{Hassani2007,
   abstract = {In recent years Singular Spectrum Analysis (SSA), used as a powerful technique in time series analysis, has been developed and applied to many practical problems. In this paper, the performance of the SSA technique has been considered by applying it to a well-known time series data set, namely, monthly accidental deaths in the USA. The results are compared with those obtained using Box-Jenkins SARIMA models, the ARAR algorithm and the Holt-Winter algorithm (as described in Brockwell and Davis (2002)). The results show that the SSA technique gives a much more accurate forecast than the other methods indicated above.},
   author = {Hossein Hassani},
   journal = {Journal of Data Science},
   keywords = {ARAR algorithm,Box-Jenkins SARIMA models,Holt-Winter algorithm,USA monthly accidental deaths series,singular spectrum analysis (SSA)},
   pages = {239-257},
   title = {Munich Personal RePEc Archive Singular Spectrum Analysis: Methodology and Comparison Singular Spectrum Analysis: Methodology and Comparison},
   volume = {4991},
   year = {2007},
}
@misc{Hassani2007,
   abstract = {In recent years Singular Spectrum Analysis (SSA), used as a powerful technique in time series analysis, has been developed and applied to many practical problems. In this paper, the performance of the SSA technique has been considered by applying it to a well-known time series data set, namely, monthly accidental deaths in the USA. The results are compared with those obtained using Box-Jenkins SARIMA models, the ARAR algorithm and the Holt-Winter algorithm (as described in Brockwell and Davis (2002)). The results show that the SSA technique gives a much more accurate forecast than the other methods indicated above.},
   author = {Hossein Hassani},
   journal = {Journal of Data Science},
   keywords = {ARAR algorithm,Box-Jenkins SARIMA models,Holt-Winter algorithm,USA monthly accidental deaths series,singular spectrum analysis (SSA)},
   pages = {239-257},
   title = {Singular Spectrum Analysis: Methodology and Comparison},
   volume = {5},
   year = {2007},
}
@article{Das2023,
   abstract = {This thorough study examines the development of visual effects (VFX) in movies from their beginning to the present, delving into the shift from practical effects to the CGI revolution and beyond. Visual effects-which include physical effects, computer-generated imagery, and optical illusions-are essential to storytelling because they allow audiences to escape reality and enter fantastical realms. Filmmakers such as Georges Méliès, who pioneered practical effects in the late 19th and early 20th centuries, set the historical trip in motion with their early experiments. The CGI period of the 1990s was made possible by the subsequent rise of special effects in the 1970s and 1980s, which was characterized by optical printers and blue/green screen technology. With films like "Jurassic Park," which epitomized the CGI revolution, visual storytelling entered a new era and demonstrated the power of computer-generated images. The essay also explores how the future of visual effects may be impacted by technology developments like as motion capture, virtual reality, augmented reality, and artificial intelligence. Examining classic films like as Méliès' "A Trip to the Moon" and James Cameron's "Avatar," case studies demonstrate how important special effects are to a successful picture. The final section examines how technology continues to impact visual effects while speculating on potential future developments that could completely alter the artistic terrain of filmmaking.},
   author = {Soumen Das},
   issue = {November},
   journal = {JETIR2311442 Journal of Emerging Technologies and Innovative Research},
   keywords = {CGI,Cinematic Storytelling,Future of Visual Effects,Georges Méliès,Optical Illusions,Practical Effects,Special Effects,Visual Effects},
   title = {the Evolution of Visual Effects in 
Cinema: a Journey From Practical 
Effects To Cgi},
   volume = {10},
   url = {www.jetir.org},
   year = {2023},
}
@article{Valdivieso2021,
   abstract = {La importancia de los efectos visuales en las lucha en tv y cine A importância dos efeitos visuais nas lutas na tv e no filme Mijail Luis Intriago-Valdivieso I},
   author = {Mijail Luis Intriago Valdivieso},
   issue = {1},
   pages = {179-212},
   title = {The importance of visual effects in fights in tv and film The importance of visual effects in fights in tv and film},
   volume = {7},
   url = {http://dominiodelasciencias.com/ojs/index.php/es/index},
   year = {2021},
}
@article{Kwasi2016,
   author = {Emmanuel Kwasi},
   issue = {67748},
   title = {Munich Personal RePEc Archive Box-Jenkins modelling and forecasting of Brent crude oil price},
   year = {2016},
}
@article{Petukhova2018,
   author = {Tatiana Petukhova and Davor Ojkic and Beverly Mcewen and Rob Deardon and Zvonimir Poljak},
   isbn = {1111111111},
   pages = {1-17},
   title = {Assessment of autoregressive integrated moving average ( ARIMA ), generalized linear autoregressive moving average ( GLARMA ), and random forest ( RF ) time series regression models for predicting influenza A virus frequency in swine in Ontario , Canada},
   year = {2018},
}
@article{Aamir2018,
   author = {Muhammad Aamir and Ani Shabri and Muhammad Ishaq},
   issue = {4},
   keywords = {arima,crude oil,eemd,forecasting,reconstruction},
   pages = {471-483},
   title = {Improving forecasting accuracy of crude oil price using decomposition ensemble model with reconstruction of IMFs based on ARIMA model},
   volume = {14},
   year = {2018},
}
@article{Sharma2021,
   abstract = {In this article we will provide the reader the over view of Visual Effect Technology, the evolution of VFX technology from 90ies till now how VFX has played an important role in film industry. In this article we will observe and evaluate how digital compositing is essential part of cinematography what types of VFX techniques film industry is using to give realistic look to the live action and 3D movies. What types of software's is been used to increase the production efficiency of the films. The term CGI (Computer Generated Images) which is well known to everyone these days is the step toward Post production and how the VFX artists are dealing with it.},
   author = {Deepak Sharma},
   issue = {1},
   keywords = {advance-level-of-vfx,and 3d animation,bullet time visual,cgi,chroma,com,compositing,effects,https,maac-animation,matte painting,picture courtesy,rotoscoping,stop animation,virtual cinematography,visual effects,www},
   pages = {217-220},
   title = {Ijmer: Visual Effects Now and Then},
   volume = {514},
   year = {2021},
}
@article{Chen2019,
   author = {Engu Chen and Xin James He},
   issue = {4},
   title = {Crude Oil Price Prediction with Decision Tree Based Regression Approach Crude Oil Price Prediction with Decision Tree Based Regression Approach},
   volume = {27},
   year = {2019},
}
@article{Hashim2019,
   abstract = {Globalization of technology primarily in the field of film, media and communication studies has also impacted the creativity in visual presentation and storytelling. The occurrence of technological changes that involve creative work will undoubtedly lead to a new assessment of creativity. Hence, technology and creativity are likely to represent a new creative possibility and measurement in the field of film production. Digital Visual Effects (DVFx) provides new kind of creativity based on technology to the creative visual presentation and creative narrative enhancement. We have learned that story and narratives are the priorities that need to be secure in a movie; however, the spectacular element produced by using DVFx show the progress and development of technology used in the film production process, especially to the creative narrative. Hence the question that needs to address is; how these elements of technology integrated with the story and narrative filmmaking? Generally, this article will focus on the role and impact of DVFx as narrative techno-enhancement in the storytelling, and narrative presentation compared the technical visual presentation aspect. Precisely, this article analyses the impact on DVFx among professionals in Malaysia, India, and Australia’s film industries to enhance creative narrative performance. Narrative interstate relies on our understanding of the use of technology to create and convey stories. Presentation of stories also means communicating and transferring the meaning to the audiences. In addition to functioning as narrative techno-enhancement, DVFx opens the exploration of value in creative storytelling such as digital narrative and digital interactive storytelling for the audience in the 21st century.},
   author = {Hasrul Hashim},
   doi = {10.17576/JKMJC-2019-3501-02},
   issn = {22891528},
   issue = {1},
   journal = {Jurnal Komunikasi: Malaysian Journal of Communication},
   keywords = {Digital storytelling,Digital visual effects,Interactive,Movies,Narrative},
   pages = {17-28},
   title = {Narrative techno-enhancement: The impact of the digital visual effects (DVFx) in creative narrative performance},
   volume = {35},
   year = {2019},
}
@article{Willmott2005,
   author = {Cort J Willmott and Kenji Matsuura},
   issue = {1},
   journal = {Climate Research},
   pages = {79-82},
   title = {Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance},
   volume = {30},
   year = {2005},
}
@article{Nikiforov2020,
   author = {Georgy V Nikiforov and Dmitry A Borovikov and Alexander G Dyakonov},
   issue = {15},
   journal = {Energies},
   pages = {3831},
   title = {On the issue of choosing a quality dataset for short-term forecasting of oil prices},
   volume = {13},
   year = {2020},
}
@article{Wickham2014,
   author = {Hadley Wickham},
   issue = {10},
   journal = {Journal of Statistical Software},
   pages = {1-23},
   title = {Tidy data},
   volume = {59},
   year = {2014},
}
@article{Liaw2002,
   author = {Andy Liaw and Matthew Wiener},
   issue = {3},
   journal = {R news},
   pages = {18-22},
   title = {Classification and regression by randomForest},
   volume = {2},
   year = {2002},
}
@misc{Agency2005,
   author = {International Energy Agency},
   title = {Oil market report},
   url = {https://www.iea.org/reports/oil-market-report},
   year = {2005},
}
@misc{,
   author = {Institute of Energy Security},
   title = {Impact of rising oil prices on Ghana's economy},
   url = {https://www.ies.gov.gh/oil-prices-impact-report},
   year = {2022},
}
@book{Hyndman2018,
   author = {Rob J Hyndman and George Athanasopoulos},
   publisher = {OTexts},
   title = {Forecasting: principles and practice},
   year = {2018},
}
@article{Fattouh2011,
   author = {Bassam Fattouh},
   journal = {Oxford Institute for Energy Studies},
   title = {An anatomy of the crude oil pricing system},
   year = {2011},
}
@article{Brownlee2020,
   author = {Jason Brownlee},
   journal = {Machine Learning Mastery},
   title = {Data Preparation for Machine Learning: Data Cleaning, Feature Selection, Data Transforms, Validation, and Much More},
   year = {2020},
}
@article{Brownlee2018,
   author = {Jason Brownlee},
   journal = {Machine Learning Mastery},
   title = {How to Handle Missing Data},
   url = {https://machinelearningmastery.com/handle-missing-data-python/},
   year = {2018},
}
@article{Breiman2001,
   author = {Leo Breiman},
   issue = {1},
   journal = {Machine Learning},
   pages = {5-32},
   title = {Random forests},
   volume = {45},
   year = {2001},
}
@article{Baumeister2016,
   author = {Christiane Baumeister and Lutz Kilian},
   issue = {1},
   journal = {Journal of Economic Perspectives},
   pages = {139-160},
   title = {Forty years of oil price fluctuations: Why the price of oil may still surprise us},
   volume = {30},
   year = {2016},
}
@article{Breiman1996,
   author = {Leo Breiman},
   issue = {2},
   journal = {Machine Learning},
   pages = {123-140},
   title = {Bagging predictors},
   volume = {24},
   year = {1996},
}
@article{Aamir2018,
   abstract = {<p>The accuracy of crude oil price forecasting is more important especially for economic development and is considered a lifeblood of the industry. Hence, in this paper, a decomposition-ensemble model with the reconstruction of intrinsic mode functions (IMFs) is proposed for forecasting the crude oil prices based on the well-known autoregressive moving average (ARIMA) model. Essentially, the reconstruction of IMFs enhanced the forecasting accuracy of the existing decomposition ensemble models. The proposed methodology works in four steps: decomposition of the complex data into several IMFs using EEMD, reconstruction of IMFs based on order of ARIMA model, prediction of every reconstructed IMF, and finally ensemble the prediction of every IMF for the final output. A case study is carried out using two crude oil prices time series (i.e. Brent and West Texas Intermediate (WTI)). The empirical results exhibited that the reconstruction of IMFs based on order of ARIMA model was adequate and provided the best forecast. To check the correctness, robustness and generalizability simulations were also carried out.</p>},
   author = {Muhammad Aamir and Ani Shabri and Muhammad Ishaq},
   doi = {10.11113/mjfas.v14n4.1013},
   issn = {2289-599X},
   issue = {4},
   journal = {Malaysian Journal of Fundamental and Applied Sciences},
   month = {12},
   pages = {471-483},
   title = {Improving forecasting accuracy of crude oil prices using decomposition ensemble model with reconstruction of IMFs based on ARIMA model},
   volume = {14},
   year = {2018},
}
@article{Kohlscheen2024,
   author = {Emanuel Kohlscheen},
   doi = {10.1007/s00181-023-02480-0},
   issn = {0377-7332},
   issue = {2},
   journal = {Empirical Economics},
   month = {2},
   pages = {927-943},
   title = {Forecasting oil prices with random forests},
   volume = {66},
   year = {2024},
}
@article{Hasan2024,
   abstract = {<p> To efficiently capture diverse fluctuation profiles in forecasting crude oil prices, we here propose to combine heterogenous predictors for forecasting the prices of crude oil. Specifically, a forecasting model is developed using blended ensemble learning that combines various machine learning methods, including <italic>k</italic> -nearest neighbor regression, regression trees, linear regression, ridge regression, and support vector regression. Data for Brent and WTI crude oil prices at various time series frequencies are used to validate the proposed blending ensemble learning approach. To show the validity of the proposed model, its performance is further benchmarked against existing individual and ensemble learning methods used for predicting crude oil price, such as lasso regression, bagging lasso regression, boosting, random forest, and support vector regression. We demonstrate that our proposed blending-based model dominates the existing forecasting models in terms of forecasting errors for both short- and medium-term horizons. </p>},
   author = {Mahmudul Hasan and Mohammad Zoynul Abedin and Petr Hajek and Kristof Coussement and Md. Nahid Sultan and Brian Lucey},
   doi = {10.1007/s10479-023-05810-8},
   issn = {0254-5330},
   journal = {Annals of Operations Research},
   month = {1},
   title = {A blending ensemble learning model for crude oil price forecasting},
   year = {2024},
}
@article{Yaziz2011,
   author = {Siti Roslindar Yaziz and Maizah Hura Ahmad and Lee Chee Nian and Noryanti Muhammad},
   doi = {10.3923/jas.2011.1129.1135},
   issn = {18125654},
   issue = {7},
   journal = {Journal of Applied Sciences},
   month = {3},
   pages = {1129-1135},
   title = {A Comparative Study on Box-Jenkins and Garch Models in Forecasting Crude Oil Prices},
   volume = {11},
   year = {2011},
}
@article{Xiang2013,
   abstract = {<p>International crude oil price is the referential scale of spot crude oil price and refined oil price. This paper made an analysis and prediction of Brent crude oil price by ARIMA model based on its price data from November 2012 to April 2013. It indicated that model ARIMA (1,1,1) possessed good prediction effect and can be used as short-term prediction of International crude oil price.</p>},
   author = {Ying Xiang and Xiao Hong Zhuang},
   doi = {10.4028/www.scientific.net/AMR.798-799.979},
   issn = {1662-8985},
   journal = {Advanced Materials Research},
   month = {9},
   pages = {979-982},
   title = {Application of ARIMA Model in Short-Term Prediction of International Crude Oil Price},
   volume = {798-799},
   year = {2013},
}
@article{Ahmed2014,
   author = {Ahmed},
   doi = {10.3844/ajassp.2014.425.432},
   issn = {1546-9239},
   issue = {3},
   journal = {American Journal of Applied Sciences},
   month = {3},
   pages = {425-432},
   title = {DAILY CRUDE OIL PRICE FORECASTING MODEL USING ARIMA, GENERALIZED AUTOREGRESSIVE CONDITIONAL HETEROSCEDASTIC AND SUPPORT VECTOR MACHINES},
   volume = {11},
   year = {2014},
}
@article{Breiman2001,
   author = {Leo Breiman},
   doi = {10.1023/A:1010933404324},
   issn = {08856125},
   issue = {1},
   journal = {Machine Learning},
   pages = {5-32},
   title = {Random Forests},
   volume = {45},
   year = {2001},
}
@article{Jaccard1901,
   author = {P Jaccard},
   journal = {Bull. Soc. Vaudoise Sci. Nat.},
   pages = {547-579},
   title = {Étude comparative de la distribution florale dans une portion des Alpes et des Jura},
   volume = {37},
   year = {1901},
}
@book{Salton1986,
   author = {G Salton and M J McGill},
   city = {New York, NY, USA},
   publisher = {McGraw-Hill},
   title = {Introduction to Modern Information Retrieval},
   year = {1986},
}
@article{Spearman1904,
   author = {C Spearman},
   issue = {1},
   journal = {Am. J. Psychol.},
   pages = {72-101},
   title = {The proof and measurement of association between two things},
   volume = {15},
   year = {1904},
}
@article{Lin1991,
   author = {J Lin},
   issue = {1},
   journal = {IEEE Trans. Inf. Theory},
   pages = {145-151},
   title = {Divergence measures based on the Shannon entropy},
   volume = {37},
   year = {1991},
}
@article{Kullback1951,
   author = {S Kullback and R A Leibler},
   issue = {1},
   journal = {Ann. Math. Statist.},
   pages = {79-86},
   title = {On information and sufficiency},
   volume = {22},
   year = {1951},
}
@inproceedings{McSherry2007,
   author = {F McSherry and K Talwar},
   journal = {Proc. IEEE Symp. Found. Comput. Sci.},
   pages = {94-103},
   title = {Mechanism design via differential privacy},
   year = {2007},
}
@article{Su2009,
   author = {X Su and T M Khoshgoftaar},
   journal = {Adv. Artif. Intell.},
   pages = {1-19},
   title = {A survey of collaborative filtering techniques},
   volume = {2009},
   year = {2009},
}
@article{Floridi2018,
   author = {Luciano Floridi and Josh Cowls and Monica Beltrametti and Raja Chatila and Patrice Chazerand and Virginia Dignum and Christoph Luetge and Robert Madelin and Ugo Pagallo and Francesca Rossi and others},
   issue = {4},
   journal = {Minds and Machines},
   pages = {689-707},
   title = {AI4People—An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations},
   volume = {28},
   year = {2018},
}
@article{Rocher2019,
   author = {Luc Rocher and Jonathan M Hendrickx and Yves-Alexandre de Montjoye},
   issue = {1},
   journal = {Nature Communications},
   pages = {1-9},
   title = {Estimating the success of re-identifications in incomplete datasets using generative models},
   volume = {10},
   year = {2019},
}
@article{Dwork2014,
   author = {Cynthia Dwork and Aaron Roth},
   issue = {3-4},
   journal = {Foundations and Trends in Theoretical Computer Science},
   pages = {211-407},
   title = {The algorithmic foundations of differential privacy},
   volume = {9},
   year = {2014},
}
@inproceedings{Mitchell2019,
   author = {Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah Raji and Timnit Murakawa},
   journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
   pages = {220-229},
   title = {Model cards for model reporting},
   year = {2019},
}
@inproceedings{,
   author = {Nina Grgic-Hlaca and Muhammad Bilal Zafar and Krishna P Gummadi and Adrian Weller},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   pages = {51-60},
   title = {Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning},
   year = {2018},
}
@article{Bellamy2019,
   author = {Rachel K E Bellamy and Kuntal Dey and Michael Hind and Samuel C Hoffman and Stephanie Houde and Jasjeet Kalita and Aleksandra Mojsilovic and Sameep Natesan and Karthikeyan Natesan Rattan and Prasanna Sattigeri and others},
   issue = {4/5},
   journal = {IBM Journal of Research and Development},
   pages = {4:1–4:15},
   title = {AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias},
   volume = {63},
   year = {2019},
}
@inproceedings{Chaney2018,
   author = {Allison J B Chaney and Brandon M Stewart and Barbara E Engelhardt},
   journal = {Proceedings of the 12th ACM Conference on Recommender Systems},
   pages = {224-232},
   title = {How algorithmic confounding in recommendation systems increases homogeneity and decreases utility},
   year = {2018},
}
@inproceedings{Yadati2022,
   author = {Karthik Yadati and Amar Kant Soni and Nripendra Kumar and Purnima Rao and Hari Koppula and Matthew Lease},
   journal = {Proceedings of the ACM International Conference on Web Search and Data Mining (WSDM)},
   pages = {1234-1242},
   title = {AotM-2011: A Large-scale Multilingual Dataset of Music Listening Histories},
   year = {2022},
}
@inproceedings{Zangerle2018,
   author = {Eva Zangerle and Martin Pichl and Markus Schedl},
   journal = {Proceedings of the Recommender Systems Challenge},
   pages = {1-6},
   title = {The Spotify Million Playlist Dataset Challenge},
   year = {2018},
}
@inproceedings{Sturm2021,
   author = {Bob L Sturm},
   journal = {Proceedings of the 22nd International Society for Music Information Retrieval Conference (ISMIR)},
   pages = {789-795},
   title = {The 30Music Dataset: A Collection of Music Listening Histories and Metadata for Research},
   year = {2021},
}
@inproceedings{Zhuang2020,
   author = {Feng Zhuang and Jin Luo and Xinge Zhou and Qingming He},
   journal = {Proceedings of the International Joint Conference on Neural Networks (IJCNN)},
   pages = {1-8},
   title = {Listening Behavior Simulation Using Generative Adversarial Networks},
   year = {2020},
}
@inproceedings{Mao2018,
   author = {Hong-Yu Henry Mao and Taylor Shin and Garrison W Cottrell},
   journal = {Proceedings of the 12th International Conference on Semantic Computing (ICSC)},
   pages = {377-382},
   title = {DeepJ: Style-Specific Music Generation},
   year = {2018},
}
@inproceedings{Engel2017,
   author = {Jesse Engel and Cuurt Resnick and Adam Roberts and Sander Dieleman and Mohammad Norouzi and Douglas Eck and Karen Simonyan},
   journal = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
   pages = {1068-1077},
   title = {Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders},
   year = {2017},
}
@inproceedings{Anand2020,
   author = {Pranav Anand and Kushal Singhal and Jay Prakash Verma},
   journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
   pages = {1-9},
   title = {Generating Hierarchical Structures Using Generative Adversarial Networks},
   year = {2020},
}
@inproceedings{Yu2017,
   author = {Lantao Yu and Weinan Zhang and Jun Wang and Yong Yu},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   pages = {2852-2858},
   title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
   year = {2017},
}
@article{Zhang2017,
   author = {Jinyang Zhang and Graham Cormode and Camellia M Procopiuc and Divesh Srivastava and Xiaokui Xiao},
   issue = {4},
   journal = {ACM Transactions on Database Systems (TODS)},
   pages = {1-41},
   title = {PrivBayes: Private Data Release via Bayesian Networks},
   volume = {42},
   year = {2017},
}
@article{Xie2018,
   author = {Lei Xie and Kaiming Lin and Shuang Wang and Fengxin Wang and Jiayu Zhou},
   journal = {arXiv preprint arXiv:1802.0673},
   title = {Differentially Private Generative Adversarial Network},
   year = {2018},
}
@inproceedings{Dwork2006,
   author = {Cynthia Dwork},
   journal = {Proceedings of the 33rd International Colloquium on Automata, Languages and Programming (ICALP)},
   pages = {1-12},
   title = {Differential Privacy},
   year = {2006},
}
@article{Xu2018,
   author = {Lei Xu and Kalyan Veeramachaneni},
   journal = {arXiv preprint arXiv:1811.1126},
   title = {Synthesizing Tabular Data Using Generative Adversarial Networks},
   year = {2018},
}
@inproceedings{Yoon2019,
   author = {Jasmine Yoon and Daniel Jarrett and Mihaela van der Schaar},
   journal = {Advances in Neural Information Processing Systems},
   pages = {5509-5519},
   title = {Time-series Generative Adversarial Networks},
   year = {2019},
}
@inproceedings{Radford2016,
   author = {Alec Radford and Luke Metz and Soumith Chintala},
   journal = {Proceedings of the International Conference on Learning Representations (ICLR)},
   title = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
   year = {2016},
}
@inproceedings{Goodfellow2014,
   author = {Ian Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
   journal = {Advances in Neural Information Processing Systems},
   pages = {2672-2680},
   title = {Generative Adversarial Networks},
   year = {2014},
}
@inproceedings{Sakshaug2010,
   author = {Joseph W Sakshaug and Trivellore E Raghunathan and Donald B Rubin},
   journal = {Proceedings of the Survey Research Methods Section, American Statistical Association},
   pages = {1494-1503},
   title = {Synthetic Data Generation for Small Area Estimation in Survey Sampling},
   year = {2010},
}
@inproceedings{Patki2016,
   author = {Neha Patki and Roy Wedge and Kalyan Veeramachaneni},
   journal = {Proceedings of the IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
   pages = {399-410},
   title = {The Synthetic Data Vault},
   year = {2016},
}
@article{Drechsler2011,
   author = {Jörg Drechsler},
   institution = {Otto-Friedrich-Universität Bamberg},
   title = {Generating Synthetic Datasets for Statistical Disclosure Control},
   year = {2011},
}
@inproceedings{Schedl2014,
   author = {Markus Schedl and Cynthia C S Liem and Geoffroy Peeters and Nicola Orio},
   journal = {Proceedings of the 4th International Conference on Multimedia Retrieval},
   pages = {381-388},
   title = {A Professionally Annotated and Enriched Multimodal Data Set on Popular Music},
   year = {2014},
}
@article{Knees2020,
   author = {Peter Knees and Markus Schedl and Masataka Goto},
   issue = {1},
   journal = {Transactions of the International Society for Music Information Retrieval},
   pages = {165-179},
   title = {Intelligent User Interfaces for Music Discovery},
   volume = {3},
   year = {2020},
}
@inproceedings{Schedl2019,
   author = {Markus Schedl and Bruce Ferwerda and Audrey Laplante},
   journal = {Proceedings of the 4th International Workshop on Music Recommendation and Discovery (WOMRAD)},
   title = {Exploring Cultural Differences in Music Taste and Music Preference Prediction using the LFM-1b Dataset},
   year = {2019},
}
@article{Schedl2017,
   author = {Markus Schedl},
   issue = {1},
   journal = {International Journal of Multimedia Information Retrieval},
   pages = {71-84},
   title = {Investigating Country-Specific Music Preferences and Music Recommendation Algorithms with the LFM-1b Dataset},
   volume = {6},
   year = {2017},
}
@inproceedings{Schedl2016,
   author = {Markus Schedl},
   journal = {Proceedings of the ACM International Conference on Multimedia Retrieval},
   pages = {103-110},
   title = {The LFM-1b Dataset for Music Retrieval and Recommendation},
   year = {2016},
}
@inproceedings{,
   author = {Aaron Van Den Oord and Sander Dieleman and Benjamin Schrauwen},
   journal = {Advances in Neural Information Processing Systems},
   pages = {2643-2651},
   title = {Deep Content-based Music Recommendation},
   year = {2013},
}
@inproceedings{Wang2014,
   author = {Xinxi Wang and Yi Wang and Ye Wang},
   journal = {Proceedings of the 22nd ACM International Conference on Multimedia},
   pages = {627-636},
   title = {Improving Content-based and Hybrid Music Recommendation using Deep Learning},
   year = {2014},
}
@inproceedings{,
   author = {Thierry Bertin-Mahieux and Daniel P W Ellis and Brian Whitman and Paul Lamere},
   journal = {Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR)},
   pages = {591-596},
   title = {The Million Song Dataset},
   year = {2011},
}
@inproceedings{Vall2018,
   author = {Andreu Vall and Markus Schedl and Christine Bauer},
   journal = {Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization},
   pages = {281-285},
   title = {Temporal context-aware music recommendation},
   year = {2018},
}
@article{Hsieh2021,
   author = {Huei-Yun Hsieh and Pin-Neng Wu},
   issue = {5},
   journal = {Multimedia Tools and Applications},
   pages = {7325-7346},
   title = {A user profile construction method based on Chinese word embedding for music recommendation},
   volume = {80},
   year = {2021},
}
@inproceedings{Rabiaa2020,
   author = {Omar Rabiaa and Boukhers Oussama and Neggaz Mourad},
   journal = {Proceedings of the 22nd International Conference on Big Data Analytics and Knowledge Discovery},
   pages = {262-273},
   title = {Generating realistic synthetic music datasets using deep learning},
   year = {2020},
}
@inbook{Gursoy2020,
   author = {Deniz Gursoy},
   journal = {Advances in Data Mining and Database Management},
   pages = {146-164},
   publisher = {IGI Global},
   title = {Synthetic data generation for machine learning},
   year = {2020},
}
@inproceedings{Murali2021,
   author = {Tejas Murali and Lona Swart and Matthew Lease},
   journal = {Proceedings of the 2nd Workshop on Designing Human-Centric MIR Systems},
   pages = {27-33},
   title = {Diversity and fairness metrics for generated music recommendations},
   year = {2021},
}
@article{Barkanyi2020,
   author = {Orsolya Barkanyi and Camila Caiado},
   journal = {arXiv preprint arXiv:2010.0405},
   title = {Fair recommender systems: Mitigating algorithmic bias in the music industry},
   year = {2020},
}
@misc{Union2016,
   author = {European Union},
   title = {General Data Protection Regulation (GDPR)},
   year = {2016},
}
@inproceedings{Song2012,
   author = {Yang Song and Simon Dixon and Marcus Pearce},
   journal = {9th International Symposium on Computer Music Modeling and Retrieval (CMMR)},
   pages = {395-410},
   title = {A survey of music recommendation systems and future perspectives},
   year = {2012},
}
@article{Schedl2013,
   author = {Markus Schedl and Arthur Flexer and Julian Urbano},
   issue = {3},
   journal = {Journal of Intelligent Information Systems},
   pages = {523-539},
   title = {The neglected user in music information retrieval research},
   volume = {41},
   year = {2013},
}
@article{Rentfrow2003,
   author = {Peter J Rentfrow and Samuel D Gosling},
   issue = {6},
   journal = {Journal of Personality and Social Psychology},
   pages = {1236-1256},
   title = {The do re mi's of everyday life: The structure and personality correlates of music preferences},
   volume = {84},
   year = {2003},
}
@article{Schedl2018,
   author = {Markus Schedl and Hamed Zamani and Ching-Wei Chen and Yashar Deldjoo and Mehdi Elahi},
   issue = {2},
   journal = {International Journal of Multimedia Information Retrieval},
   pages = {95-116},
   title = {Current challenges and visions in music recommender systems research},
   volume = {7},
   year = {2018},
}
@inproceedings{Ferwerda2017,
   author = {Bruce Ferwerda and Marko Tkalcic and Markus Schedl},
   journal = {Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization},
   pages = {285-288},
   title = {Personality traits and music genres: What do people prefer to listen to?},
   year = {2017},
}
@article{Knees2013,
   author = {Peter Knees and Markus Schedl},
   issue = {1},
   journal = {ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)},
   pages = {1-21},
   title = {A survey of music similarity and recommendation from music context data},
   volume = {10},
   year = {2013},
}
@article{Adomavicius2005,
   author = {Gediminas Adomavicius and Alexander Tuzhilin},
   issue = {6},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   pages = {734-749},
   title = {Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions},
   volume = {17},
   year = {2005},
}
@article{,
   author = {Dadson Awunyo-Vitor and Solomon Samanhyia and Elijah Addo Bonney},
   doi = {10.1080/23322039.2018.1496551},
   issn = {2332-2039},
   issue = {1},
   journal = {Cogent Economics & Finance},
   month = {1},
   pages = {1496551},
   title = {Do oil prices influence economic growth in Ghana? An empirical analysis},
   volume = {6},
   year = {2018},
}
@misc{,
   author = {Wikipedia},
   title = {Brent Wiki},
   url = {https://en.wikipedia.org/wiki/Brent_Crude},
}
@misc{,
   author = {Bank of Ghana},
   title = {Commodity Prices - Bank of Ghana},
   url = {https://www.bog.gov.gh/%20economic-%20data/commodity-prices},
}
@article{Phutela2020,
   author = {N Phutela and G Arushi and S Gupta and G Gabrani},
   doi = {10.21203/rs.3.rs-32472/v1},
   journal = {Infect. Dis. (Auckl.)},
   pages = {1-9},
   title = {Forecasting the Stability of COVID-19 on Indian Dataset with Prophet Logistic Growth Model},
   year = {2020},
}
@inproceedings{Borowik2019,
   author = {G Borowik and Z M Wawrzyniak and P Cichosz},
   doi = {10.1109/ICSENG.2018.8638179},
   journal = {26th Int. Conf. Syst. Eng. ICSEng 2018 - Proc.},
   title = {Time series analysis for crime forecasting},
   year = {2019},
}
@inproceedings{Samal2019,
   author = {K K R Samal and K S Babu and S K Das and A Acharaya},
   doi = {10.1145/3355402.3355417},
   journal = {ACM Int. Conf. Proceeding Ser.},
   pages = {80-85},
   title = {Time series based air pollution forecasting using SARIMA and prophet model},
   year = {2019},
}
@article{,
   author = {E Žunić and K Korjenić and K Hodžić and D Đonko},
   doi = {10.5121/ijcsit.2020.12203},
   journal = {Int. J. Comput. Sci. Inf. Technol.},
   pages = {23-36},
   title = {Application of Facebook's Prophet Algorithm for Successful Sales Forecasting Based on Real-world Data},
   volume = {12},
   year = {2020},
}
@inproceedings{Duarte2019,
   author = {D Duarte and J Faerman},
   doi = {10.5121/csit.2019.91810},
   journal = {CSIT},
   pages = {123-133},
   title = {Comparison of Time Series Prediction of Healthcare Emergency Department Indicators with ARIMA and Prophet},
   year = {2019},
}
@article{Weytjens2019,
   author = {H Weytjens and E Lohmann and M Kleinsteuber},
   doi = {10.1007/s10660-019-09362-7},
   journal = {Electron. Commer. Res.},
   title = {Cash flow prediction: MLP and LSTM compared to ARIMA and Prophet},
   year = {2019},
}
@article{,
   author = {H E Kızılöz},
   doi = {10.31590/ejosat.araconf48},
   journal = {Eur. J. Sci. Technol.},
   pages = {370-375},
   title = {Bilimsel Makalelerin Atıf Sayısı Tahmini},
   year = {2020},
}
@article{Aguilera2019,
   author = {H Aguilera and C Guardiola-Albert and N Naranjo-Fernández and C Kohfahl},
   doi = {10.1080/02626667.2019.1651933},
   journal = {Hydrol. Sci. J.},
   pages = {1504-1518},
   title = {Towards flexible groundwater-level prediction for adaptive water management: using Facebook's Prophet forecasting approach},
   volume = {64},
   year = {2019},
}
@article{Alpay2020,
   author = {Ö Alpay},
   doi = {10.31590/ejosat.araconf59},
   journal = {Eur. J. Sci. Technol.},
   pages = {452-456},
   title = {LSTM Mimarisi Kullanarak USD/TRY Fiyat Tahmini},
   year = {2020},
}
@article{Gultepe2019,
   author = {Y Gultepe},
   doi = {10.31590/ejosat.530347},
   journal = {Eur. J. Sci. Technol.},
   pages = {8-15},
   title = {Makine Öğrenmesi Algoritmaları ile Hava Kirliliği Tahmini Üzerine Karşılaştırmalı Bir Değerlendirme},
   year = {2019},
}
@article{,
   author = {K Oğuz and M A Pekin},
   doi = {10.31590/ejosat.452598},
   journal = {Eur. J. Sci. Technol.},
   pages = {542-551},
   title = {Yapay Sinir Ağları ile Esenboğa Havaalanı için Sis Görüş Mesafesinin Tahmin Edilebilirliği},
   year = {2019},
}
@article{Latifoglu2020,
   author = {L Latifoglu and K B Nuralan},
   doi = {10.31590/ejosat.araconf49},
   journal = {Eur. J. Sci. Technol.},
   pages = {376-381},
   title = {Tekil Spektrum Analizi ve Uzun-Kısa Süreli Bellek Ağları ile Nehir Akım Tahmini},
   year = {2020},
}
@article{Chiroma2015,
   author = {H Chiroma and S Abdulkareem and T Herawan},
   doi = {10.1016/j.apenergy.2014.12.045},
   journal = {Appl. Energy},
   pages = {266-273},
   title = {Evolutionary Neural Network model for West Texas Intermediate crude oil price prediction},
   volume = {142},
   year = {2015},
}
@article{Abdollahi2020,
   author = {H Abdollahi and S B Ebrahimi},
   doi = {10.1016/j.energy.2020.117520},
   journal = {Energy},
   pages = {117520},
   title = {A new hybrid model for forecasting Brent crude oil price},
   volume = {200},
   year = {2020},
}
@article{Gupta2020,
   author = {N Gupta and S Nigam},
   doi = {10.1016/j.procs.2020.03.136},
   journal = {Procedia Comput. Sci.},
   pages = {642-647},
   title = {Crude Oil Price Prediction using Artificial Neural Network},
   volume = {170},
   year = {2020},
}
@article{Bristone2019,
   author = {M Bristone and R Prasad and A A Abubakar},
   doi = {10.1016/j.petlm.2019.11.009},
   journal = {Petroleum},
   pages = {1-9},
   title = {CPPCNDL: Crude oil price prediction using complex network and deep learning algorithms},
   year = {2019},
}
@inproceedings{Guo2019,
   author = {J Guo},
   doi = {10.1109/MLBDBI48998.2019.00054},
   journal = {Proc - 2019 Int Conf Mach Learn Big Data Bus Intell MLBDBI 2019},
   pages = {241-247},
   title = {Oil price forecast using deep learning and ARIMA},
   year = {2019},
}
@article{Olofin2020,
   author = {S O Olofin and T F Oloko and K O Isah and A E Ogbonna},
   doi = {10.1108/IJESM-05-2019-0004},
   journal = {Int. J. Energy Sect. Manag.},
   pages = {729-744},
   title = {Crude oil price–shale oil production nexus: a predictability analysis},
   volume = {14},
   year = {2020},
}
@inproceedings{Abdullah2010,
   author = {S N Abdullah and X Zeng},
   doi = {10.1109/IJCNN.2010.5596602},
   journal = {Proc. Int. Jt. Conf. Neural Networks},
   pages = {44},
   title = {Machine learning approach for crude oil price prediction with Artificial Neural Networks-Quantitative (ANN-Q) model},
   year = {2010},
}
@misc{Ishaq2020,
   author = {M F Ishaq},
   title = {Data Mining Forcasting Oil and Gas Development Company Ltd. Share Prices Using Orange},
   year = {2020},
}
@inproceedings{Gabralla2013,
   author = {L A Gabralla and R Jammazi and A Abraham},
   doi = {10.1109/ICCEEE.2013.6634021},
   journal = {Proc. - 2013 Int. Conf. Comput. Electr. Electron. Eng. 'Research Makes a Differ. ICCEEE 2013},
   pages = {674-679},
   title = {Oil price prediction using ensemble machine learning},
   year = {2013},
}
@article{Wang2020,
   author = {J Wang and C Lei and M Guo},
   doi = {10.1016/j.petrol.2020.107240},
   journal = {J. Pet. Sci. Eng.},
   pages = {107240},
   title = {Daily natural gas price forecasting by a weighted hybrid data-driven model},
   volume = {192},
   year = {2020},
}
@inproceedings{Khashman2011,
   author = {A Khashman and N I Nwulu},
   doi = {10.1109/SAMI.2011.5738868},
   journal = {9th IEEE Int. Symp. Appl. Mach. Intell. Informatics, SAMI 2011},
   pages = {165-169},
   title = {Intelligent prediction of crude oil price using Support Vector Machines},
   year = {2011},
}
@misc{Salvi2019,
   author = {H Salvi and Avdhi Shah and Manthan Mehta and Stevina Correia},
   doi = {10.22214/ijraset.2019.11050},
   journal = {Int. J. Res. Appl. Sci. Eng. Technol.},
   pages = {315-319},
   title = {Long Short-Term Model for Brent Oil Price Forecasting},
   volume = {7},
   year = {2019},
}
@article{An2019,
   author = {J An and A Mikhaylov and N Moiseev},
   doi = {10.32479/ijeep.7597},
   journal = {Int. J. Energy Econ. Policy},
   pages = {1-6},
   title = {Oil price predictors: Machine learning approach},
   volume = {9},
   year = {2019},
}
@misc{,
   title = {978-3-030-49788-0_19},
}
@article{Bartneck2009,
   abstract = {This study emphasizes the need for standardized measurement tools for human robot interaction (HRI). If we are to make progress in this field then we must be able to compare the results from different studies. A literature review has been performed on the measurements of five key concepts in HRI: anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. The results have been distilled into five consistent questionnaires using semantic differential scales. We report reliability and validity indicators based on several empirical studies that used these questionnaires. It is our hope that these questionnaires can be used by robot developers to monitor their progress. Psychologists are invited to further develop the questionnaires by adding new concepts, and to conduct further validations where it appears necessary. © The Author(s) 2008.},
   author = {Christoph Bartneck and Dana Kulić and Elizabeth Croft and Susana Zoghbi},
   doi = {10.1007/s12369-008-0001-3},
   issn = {18754805},
   issue = {1},
   journal = {International Journal of Social Robotics},
   keywords = {Human factors,Measurement,Perception,Robot},
   pages = {71-81},
   title = {Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots},
   volume = {1},
   year = {2009},
}
@article{Heen2023,
   author = {Jon Fredrik Rasmussen Heen and Christoffer Bachke},
   institution = {Handelshøyskolen BI},
   title = {A comprehensive analysis of Brent Crude oil forecasting methods combining machine learning and quantitative models with application},
   year = {2023},
}
@article{,
   author = {Didem Güleryüz and Erdemalp Özden},
   issue = {20},
   journal = {Avrupa Bilim ve Teknoloji Dergisi},
   pages = {1-9},
   publisher = {Osman SAĞDIÇ},
   title = {The prediction of Brent crude oil trend using LSTM and Facebook prophet},
   year = {2020},
}
@inproceedings{,
   author = {Sima Siami-Namini and Neda Tavakoli and Akbar Siami Namin},
   journal = {2018 17th IEEE international conference on machine learning and applications (ICMLA)},
   pages = {1394-1401},
   title = {A comparison of ARIMA and LSTM in forecasting time series},
   year = {2018},
}
@article{Lu2021,
   author = {Hongfang Lu and Xin Ma and Minda Ma and Senlin Zhu},
   journal = {Computer Science Review},
   pages = {100356},
   publisher = {Elsevier},
   title = {Energy price prediction using data-driven models: A decade review},
   volume = {39},
   year = {2021},
}
@article{Sehgal2015,
   author = {Neha Sehgal and Krishan K Pandey},
   journal = {Energy Systems},
   pages = {479-506},
   publisher = {Springer},
   title = {Artificial intelligence methods for oil price forecasting: a review and evaluation},
   volume = {6},
   year = {2015},
}
@article{Gabralla2013,
   author = {Lubna A Gabralla and Ajith Abraham},
   journal = {International Journal of Computer Information Systems and Industrial Management Applications},
   pages = {729-740},
   title = {Computational modeling of crude oil price forecasting: A review of two decades of research},
   volume = {5},
   year = {2013},
}
@article{,
   author = {Niaz Bashiri Behmiri and José Ramos Pires Manso},
   journal = {Available at SSRN 2275428},
   title = {Crude oil price forecasting techniques: a comprehensive review of literature},
   year = {2013},
}
@article{Salvi2019,
   author = {Harsh Salvi and Avdhi Shah and Manthan Mehta and Stevina Correia},
   issue = {11},
   journal = {International Journal for Research in Applied Science and Engineering Technology},
   pages = {315-319},
   publisher = {International Journal for Research in Applied Science and Engineering~…},
   title = {Long short-term model for Brent oil price forecasting},
   volume = {7},
   year = {2019},
}
@article{Abdollahi2020,
   author = {Hooman Abdollahi and Seyed Babak Ebrahimi},
   journal = {Energy},
   pages = {117520},
   publisher = {Elsevier},
   title = {A new hybrid model for forecasting Brent crude oil price},
   volume = {200},
   year = {2020},
}
@misc{Chiroma2016,
   abstract = {When crude oil prices began to escalate in the 1970s, conventional methods were the predominant methods used in forecasting oil pricing. These methods can no longer be used to tackle the nonlinear, chaotic, non-stationary, volatile, and complex nature of crude oil prices, because of the methods’ linearity. To address the methodological limitations, computational intelligence techniques and more recently, hybrid intelligent systems have been deployed. In this paper, we present an extensive review of the existing research that has been conducted on applications of computational intelligence algorithms to crude oil price forecasting. Analysis and synthesis of published research in this domain, limitations and strengths of existing studies are provided. This paper finds that conventional methods are still relevant in the domain of crude oil price forecasting and the integration of wavelet analysis and computational intelligence techniques is attracting unprecedented interest from scholars in the domain of crude oil price forecasting. We intend for researchers to use this review as a starting point for further advancement, as well as an exploration of other techniques that have received little or no attention from researchers. Energy demand and supply projection can effectively be tackled with accurate forecasting of crude oil price, which can create stability in the oil market.},
   author = {Haruna Chiroma and Sameem Abdul-Kareem and Ahmad Shukri Mohd Noor and Adamu I. Abubakar and Nader Sohrabi Safa and Liyana Shuib and Mukhtar Fatihu Hamza and Abdulsalam Ya’u Gital and Tutut Herawan},
   doi = {10.1080/10798587.2015.1092338},
   issn = {2326005X},
   issue = {3},
   journal = {Intelligent Automation and Soft Computing},
   keywords = {Computational intelligence techniques,Crude oil price,Genetic algorithms,Hybrid intelligent systems,Individual intelligent systems,Neural networks},
   month = {7},
   pages = {449-462},
   publisher = {Taylor and Francis Inc.},
   title = {A Review on Artificial Intelligence Methodologies for the Forecasting of Crude Oil Price},
   volume = {22},
   year = {2016},
}
@misc{,
   abstract = {The goal of this article is to review the existing literature on crude oil price forecasting. We categorized the existing forecasting techniques into the two main groups of quantitative and qualitative methods; and then we performed an almost comprehensive survey on the available literature with respect to these two main forecasting techniques.},
   author = {Niaz Bashiri Behmiri and José R Pires Manso},
   keywords = {crude oil price,forecasting,literature review},
   title = {Crude oil price forecasting techniques: a comprehensive review of literature},
   url = {https://ssrn.com/abstract=2275428},
}
@misc{Lynch2002,
   author = {Michael C Lynch},
   keywords = {()},
   title = {Forecasting oil supply: theory and practice},
   year = {2002},
}
@misc{Fan2015,
   abstract = {Accurate forecasting of crude oil prices plays a significant role for supporting policy and decision making at economy and firm levels. The successive developments in econometric and artificial intelligence models provide opportunities to analyse crude oil market in depth and improve the accuracy of oil price forecasting. Past years have seen an increasing number of studies on the volatility analysis and forecasting of crude oil prices by different techniques such as econometric and artificial intelligence models. This paper aims to present a systematic review of existing tools used to model the volatility of crude oil prices. It is found that the integration of time series models with artificial intelligence models has received increasing attention in oil price forecasting owing to its satisfactory prediction performance. Also, feature extraction of oil price series with appropriate multivariate statistical analysis techniques plays an important role in improving the prediction performance.},
   author = {Liwei Fan and Huiping Li},
   doi = {10.1504/IJGEI.2015.069481},
   issn = {09547118},
   issue = {1-3},
   journal = {International Journal of Global Energy Issues},
   keywords = {Crude oil price,Energy market,Forecasting,Volatility analysis},
   pages = {5-17},
   publisher = {Inderscience Publishers},
   title = {Volatility analysis and forecasting models of crude oil prices: A review},
   volume = {38},
   year = {2015},
}
@article{,
   author = {Hamid Al Sadoon and Colin Ward and Jennifer Considine and Abdullah Al Dayel},
   doi = {10.30573/KS-2019-MP08},
   title = {A Short-Term Forecasting Model for Brent Oil Prices},
   year = {2019},
}
@article{Schedl2014,
   author = {Markus Schedl and Emilia Gómez and Julián Urbano},
   doi = {10.1561/1500000042},
   issn = {1554-0669},
   issue = {2-3},
   journal = {Foundations and Trends® in Information Retrieval},
   pages = {127-261},
   title = {Music Information Retrieval: Recent Developments and Applications},
   volume = {8},
   year = {2014},
}
@inbook{Yapriady2005,
   author = {Billy Yapriady and Alexandra L. Uitdenbogerd},
   doi = {10.1007/11554028_29},
   pages = {201-207},
   title = {Combining Demographic Data with Collaborative Filtering for Automatic Music Recommendation},
   year = {2005},
}
@article{Roy2022,
   abstract = {Recommender systems are efficient tools for filtering online information, which is widespread owing to the changing habits of computer users, personalization trends, and emerging access to the internet. Even though the recent recommender systems are eminent in giving precise recommendations, they suffer from various limitations and challenges like scalability, cold-start, sparsity, etc. Due to the existence of various techniques, the selection of techniques becomes a complex work while building application-focused recommender systems. In addition, each technique comes with its own set of features, advantages and disadvantages which raises even more questions, which should be addressed. This paper aims to undergo a systematic review on various recent contributions in the domain of recommender systems, focusing on diverse applications like books, movies, products, etc. Initially, the various applications of each recommender system are analysed. Then, the algorithmic analysis on various recommender systems is performed and a taxonomy is framed that accounts for various components required for developing an effective recommender system. In addition, the datasets gathered, simulation platform, and performance metrics focused on each contribution are evaluated and noted. Finally, this review provides a much-needed overview of the current state of research in this field and points out the existing gaps and challenges to help posterity in developing an efficient recommender system.},
   author = {Deepjyoti Roy and Mala Dutta},
   doi = {10.1186/s40537-022-00592-5},
   issn = {21961115},
   issue = {1},
   journal = {Journal of Big Data},
   keywords = {Collaborative filtering,Content-based filtering,Deep learning,Machine learning,Recommender system,Review},
   month = {12},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {A systematic review and research perspective on recommender systems},
   volume = {9},
   year = {2022},
}
@article{Zhang2017,
   abstract = {With the ever-growing volume of online information, recommender systems have been an effective strategy to overcome such information overload. The utility of recommender systems cannot be overstated, given its widespread adoption in many web applications, along with its potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. Evidently, the field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning based recommender systems. More concretely, we provide and devise a taxonomy of deep learning based recommendation models, along with providing a comprehensive summary of the state-of-the-art. Finally, we expand on current trends and provide new perspectives pertaining to this new exciting development of the field.},
   author = {Shuai Zhang and Lina Yao and Aixin Sun and Yi Tay},
   doi = {10.1145/3285029},
   month = {7},
   title = {Deep Learning based Recommender System: A Survey and New Perspectives},
   url = {http://arxiv.org/abs/1707.07435 http://dx.doi.org/10.1145/3285029},
   year = {2017},
}
@inproceedings{Zhao2013,
   abstract = {In this paper, we study collaborative filtering (CF) in an interactive setting, in which a recommender system continuously recommends items to individual users and receives interactive feedback. Whilst users enjoy sequential recommendations, the recommendation predictions are constantly refined using up-to-date feedback on the recommended items. Bringing the interactive mechanism back to the CF process is fundamental because the ultimate goal for a rec-ommender system is about the discovery of interesting items for individual users and yet users' personal preferences and contexts evolve over time during the interactions with the system. This requires us not to distinguish between the stages of collecting information to construct the user profile and making recommendations, but to seamlessly integrate these stages together during the interactive process, with the goal of maximizing the overall recommendation accuracy throughout the interactions. This mechanism naturally addresses the cold-start problem as any user can immediately receive sequential recommendations without providing ratings beforehand. We formulate the interactive CF with the probabilistic matrix factorization (PMF) framework, and leverage several exploitation-exploration algorithms to select items, including the empirical Thompson sampling and upper confidence bound based algorithms. We conduct our experiment on cold-start users as well as warm-start users with drifting taste. Results show that the proposed methods have significant improvements over several strong baselines for the MovieLens, EachMovie and Netflix datasets. Copyright 2013 ACM.},
   author = {Xiaoxue Zhao and Weinan Zhang and Jun Wang},
   doi = {10.1145/2505515.2505690},
   isbn = {9781450322638},
   journal = {International Conference on Information and Knowledge Management, Proceedings},
   keywords = {Exploitation-exploration,Interactive collaborative filtering,Personalization,Recommender systems},
   pages = {1411-1420},
   title = {Interactive collaborative filtering},
   year = {2013},
}
@article{Leskovec2014,
   abstract = {Written by leading authorities in database and Web technologies, this book is essential reading for students and practitioners alike. The popularity of the Web and Internet commerce provides many extremely large datasets from which information can be gleaned by data mining. This book focuses on practical algorithms that have been used to solve key problems in data mining and can be applied successfully to even the largest datasets. It begins with a discussion of the map-reduce framework, an important tool for parallelizing algorithms automatically. The authors explain the tricks of locality-sensitive hashing and stream processing algorithms for mining data that arrives too fast for exhaustive processing. Other chapters cover the PageRank idea and related tricks for organizing the Web, the problems of finding frequent itemsets and clustering. This second edition includes new and extended coverage on social networks, machine learning and dimensionality reduction.},
   author = {Jure Leskovec and Anand Rajaraman and Jeffrey David Ullman},
   doi = {10.1017/CBO9781139924801},
   isbn = {9781139924801},
   journal = {Mining of Massive Datasets: Second Edition},
   month = {1},
   pages = {1-458},
   publisher = {Cambridge University Press},
   title = {Mining of massive datasets: Second edition},
   url = {https://www.cambridge.org/core/books/mining-of-massive-datasets/C1B37BA2CBB8361B94FDD1C6F4E47922},
   year = {2014},
}
@article{Hu2020,
   abstract = {The recommender system is an important application in big data analytics because accurate recommendation items or high-valued suggestions can bring high profit to both commercial companies and customers. To make precise recommendations, a recommender system often needs large and fine-grained data for training. In the current big data era, data often exist in the form of isolated islands, and it is difficult to integrate the data scattered due to privacy security concerns. Moreover, privacy laws and regulations make it harder to share data. Therefore, designing a privacy-preserving recommender system is of paramount importance. Existing privacy-preserving recommender system models mainly adapt cryptography approaches to achieve privacy preservation. However, cryptography approaches have heavy overhead when performing encryption and decryption operations and they lack a good level of flexibility. In this paper, we propose a Locality Sensitive Hashing (LSH) based approach for federated recommender system. Our proposed efficient and scalable federated recommender system can make full use of multiple source data from different data owners while guaranteeing preservation of privacy of contributing parties. Extensive experiments on real-world benchmark datasets show that our approach can achieve both high time efficiency and accuracy under small privacy budgets.},
   author = {Hongsheng Hu and Gillian Dobbie and Zoran Salcic and Meng Liu and Jianbing Zhang and Xuyun Zhang},
   doi = {10.1109/CCGRID49817.2020.000-1},
   isbn = {9781728160955},
   journal = {Proceedings - 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGRID 2020},
   keywords = {differential privacy,locality sensitive hashing,recommender system},
   month = {5},
   pages = {836-842},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A Locality Sensitive Hashing Based Approach for Federated Recommender System},
   url = {https://www.researchgate.net/publication/342940774_A_Locality_Sensitive_Hashing_Based_Approach_for_Federated_Recommender_System},
   year = {2020},
}
@misc{,
   abstract = {ÊÊÊÓÑÑÑÒÒÒÖ ×Ý×ØØÑ× ×ÔÔÐÝ ÝÒÓÛÐÐÐÐÐ ÐÐ××ÓÚÖÝ ØØØÒÒÕÙÙ× ØÓ ØØØ ÔÖÓÓÐÐÑ ÓÓ ÑÑÑÑÒÒ ÔÔÖ×ÓÒÒÐÐÞÞÞ ÖÖÖÓÑÑÑÒÒÒØØÓÒ× ×ÓÖ ÒÒÓÖÑÑØØÓÒ¸ÔÖÓÓÙÙØ×ÒÒÓÖÑÑØØÓÒ¸ÔÖÓÓÙÙØ× ÓÖ ××ÖÚÚÚÚ× ×ÙÖÖÒÒ Ò ÐÐÚ Ò ØØÖÖÖØØÓÒº ÌÌÌ×× ×Ý×ØØÑ×¸¸×ÔÔÔÔÔÐÐÝ×Ý×ØØÑ×¸¸×ÔÔÔÔÔÐÐÝ ØØØ Ø¹ÒÒÒÖÖ×Ø ÒÒÒÒÒÓÖÖÓÐÐÐÐÓÖÖ¹ ØØÚ ¬ÐØØÖÖÒÒ ÒÒ××× ÓÒÒ×¸¸ÖÖÓÒÒ×¸¸ÖÖ ÖÖÚÚÒÒ ÛÛÛÛ×ÔÖÖÖÖ ×ÙÙÙÙ×× ÓÒ ØØØ Ïº ÌÌÌ ØÖÖÑÑÒÒÓÙ× ×ÖÓÛØØ ØÒ ØØØ ØÑÓÙÒØ Ó Ó Ó ÚÐ¹ ÐÐ ÐÒÒÓÖÑÑØØÓÒ ÒÒÒ ØØØ ÒÙÑÖ ÓÓ ÚÚ××ØÓÖ× ØÓ Ï ××ØØ× ×Ò ÖÖÖÖÒØ Ý Ö× ÔÓ××× ×ÓÑÑ ÑÝ ÝÐÐÐÒÒÒ× ×ÓÖ ÖÖÖÓÑÑÑÒÒÒÖ ×Ý×¹ ØØÑ×º ÌÌÌ×× ×ÖÖÖ ÔÖÓÓÙÙÙÒÒ ÒÒÒÒ ÕÙÙÐÐØÝ ÖÖÖÓÑÑÑÒÒÒØØÓÒ×¸ÔÔÖÖÓÖÑÑÒÒ ÖÖÖÓÑÑÑÒÒÒØØÓÒ×¸ÔÔÖÖÓÖÑÑÒÒ ÑÑÒÝ ÖÖÖÓÑÑÑÒÒÒØØÓÒ× ÔÔÖ ×××ÓÒÒ ÒÓÖ ÑÑÐÐÐÓÒ× ÓÓ Ù××Ö× ×ÒÒ ÒØØÑ× ×ÒÒ ÒÒÚÚÒÒ ÒÒÒÒ ÒÓÚÖÖÖÖ ÖÒ ØØØ ØØØØ ÓÓ ØØ ×ÔÔÖ××ØÝº ÁÒ ØÖÖÖÖØØÓÒÒÐ ÐÓÐÐÐÐÓÖÖØØÚ ¬ÐØØÖÖÒÒ ×Ý×ØØÑ× ØØØ ÑÓÙÒØ Ó Ó ÛÓÖÖ ÒÒÖÖÖ××× ÛÛØØ ØØØ ÒÙÑÖ ÓÓ ÔÔÖØØØØ¹ ÔÔÒØ× ×Ò ØØØ ×Ý×ØØÑº AEAEÛ ÖÖÖÓÑÑÑÒÒÒÖ ×Ý×ØØÑ ØØØÒÓÐÓÓÓÓ× ÖÖ ÒÒÒÒÒÒ ØØØØ Ò ÕÙÙÙÐÝ ÔÖÓÓÙÙÙ ÕÙÙÐÐØÝ ÖÖÖÓÑ¹ ÑÑÒÒÒØØÓÒ×¸¸ÚÒÑÑÒÒÒØØÓÒ×¸¸ÚÒ ÒÓÖ ÚÖÝ ÐÐÖÖÖ¹×××ÐÐ ÔÖÓÓÐÐÑ×º ÌÓ ÓÓÓÖÖ×× ØØØ×× ××ÙÙ× Û Ú ÜÔÐÓÖÖÖ ÖØØÑ¹¹¹××× ×ÓÐÐÐÐÓÖÖØØÚ ¬Ð¹ ØØÖÖÒÒ ØØØÒÒÕÙÙ×º ÁØØÑ¹¹¹××× ØØØÒÒÕÙÙ× ¬Ö×Ø ØÒÒÐÝÞÞ ØØØ Ù××Ö¹¹ØØÑ ÑÑØÖÖÜ ØÓ ÓÓÓÒØØØÝ ÖÖÐÐØØÓÒ×××Ô× ××ØÛÒ ÒÒ««ÖÖÒØ ØØÑ×¸¸ÒÒØØÑ×¸¸ÒÒ ØØØÒ Ù×× ØØØ×× ÖÖÐÐØØÓÒ×××Ô× ØÓ ÓÒÒÒÖÖÖØÐÝ ÝÓÑÔÙØØ ÖÖÖÓÑÑÑÒÒÒØØÓÒ× ×ÓÖ Ù××Ö×º ÁÒ ØØØ× ÔÔÔÔÖ Û ÒÒÐÝÞÞ ÞÞ««ÖÖÒØ ØØØÑ¹¹¹××× ÖÖÖÓÑÑÑÒ¹ ØØÓÒ ÒÒÒÒÖÖØØÓÒ ÒÐÐÓÖÖØØÑ×º Ï Ð Ó Ó Ó Ó Ò ØÓ ÓÓ««ÖÖÒØ Ø Ø Ø ¹ ÒÒÕÙÙ× ×ÓÖ ÖÓÑÔÙØØÒÒ ÒØØÑ¹¹ØØÑ ××ÑÑÐÐÖÖØØØ×´´ººº¸¸ØØÑ¹¹ØØÑ××ÑÑÐÐÖÖØØØ×´´ººº¸××ÑÑÐÐÖÖØØØ×´´ººº¸¸ØØÑ¹¹ØØÑ Ú×º Ó××ÒÒ ××ÑÑÐÐÖÖØØØ× ××ØÛÒ ÒØØÑ ÚØÓÖ×µ µÒÒ ««ÖÖÒØ Ø Ø Ø ÒÒÕÙÙ× ×ÓÖ ÓÓØØØÒÒÒÒ ÖÖÖÓÑÑÑÒÒÒØØÓÒ× ×ÖÓÑ ØØØÑ´´ººº¸ÛØØØ ØØØÑ´´ººº¸ØØØÑ´´ººº¸ÛØØØ ×ÙÑ Ú×º ÖÖÖÖÖ×××ÓÒ ÑÓÓÓÐµº ÒÒÐÐÝ¸ÛÒÒÐÐÝ¸Û Ü ¹ ÔÔÖÖÑÑÒØØÐÐÝ ÝÚÐÙÙØØ ÓÙÖ ÖÖ×ÙÐØ× ×ÒÒ ÒÓÑÔÔÖÖ ØØØÑ ØÓ ØØØ ××× ¹ÒÒÒÖÖ×Ø ÒÒÒÒÒÓÖ ÔÔÖÓÓÓº ÇÙÖ ÜÔÔÖÖÑÑÒØ× ×ÙÙ¹ ×Ø ØØØØ ØØØÑ¹¹¹××× ×ÐÐÓÖÖØØÑ× ÔÖÓÚÚÚÚ ÚÖÖÑÑØØØØÐÐÝ ÝÝØØØÖ ÔÔÖÖÓÖÑÑÒÒÒ ØØØÒ Ù××Ö¹¹¹××× ×ÐÐÓÖÖØØÑ×¸ÛÛÛÐÐ×ÐÐÓÖÖØØÑ×¸ÛÛÛÐÐ ÐØ ØØØ ××ÑÑ ØØÑÑ ÔÖÓÚÚÚÚÒÒ ÒÒØØØÖ ÕÙÙÐÐØÝ ØØØÒ ØØØ ØØ×Ø ØÚÐÐÐÐÐ Ù××Ö¹ ××× ×ÐÐÓÖÖØØÑ×º},
   author = {Badrul Sarwar and George Karypis and Joseph Konstan and John Riedl and ××öûö¸¸öýôô×¸ ××öûö¸¸öýôô×¸ and ¸óò×øøò¸ööööð×ºùñòºººù ¸óò×øøò¸ööööð×ºùñòºººù},
   title = {Item-Based Collaborative Filtering Recommendation Algorithms},
}
@article{Pazzani2007,
   abstract = {This chapter discusses content-based recommendation systems, i.e., systems that recommend an item to a user based upon a description of the item and a profile of the user's interests. Content-based recommendation systems may be used in a variety of domains ranging from recommending web pages, news articles, restaurants, television programs, and items for sale. Although the details of various systems differ, content-based recommendation systems share in common a means for describing the items that may be recommended, a means for creating a profile of the user that describes the types of items the user likes, and a means of comparing items to the user profile to determine what to recommend. The profile is often created and updated automatically in response to feedback on the desirability of items that have been presented to the user. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Michael J. Pazzani and Daniel Billsus},
   doi = {10.1007/978-3-540-72079-9_10/COVER},
   isbn = {3540720782},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {325-341},
   publisher = {Springer Verlag},
   title = {Content-based recommendation systems},
   volume = {4321 LNCS},
   url = {https://link.springer.com/chapter/10.1007/978-3-540-72079-9_10},
   year = {2007},
}
@article{Aytekin2019,
   abstract = {Neighborhood-based collaborative filtering (CF) methods are widely used in recommender systems because they are easy-to-implement and highly effective. One of the significant challenges of these methods is the ability to scale with the increasing amount of data since finding nearest neighbors requires a search over all of the data. Approximate nearest neighbor (ANN) methods eliminate this exhaustive search by only looking at the data points that are likely to be similar. Locality sensitive hashing (LSH) is a well-known technique for ANN search in high dimensional spaces. It is also effective in solving the scalability problem of neighborhood-based CF. In this study, we provide novel improvements to the current LSH based recommender algorithms and make a systematic evaluation of LSH in neighborhood-based CF. Besides, we make extensive experiments on real-life datasets to investigate various parameters of LSH and their effects on multiple metrics used to evaluate recommender systems. Our proposed algorithms have better running time performance than the standard LSH-based applications while preserving the prediction accuracy in reasonable limits. Also, the proposed algorithms have a large positive impact on aggregate diversity which has recently become an important evaluation measure for recommender algorithms.},
   author = {Ahmet Maruf Aytekin and Tevfik Aytekin},
   doi = {10.1007/S10844-019-00552-1/METRICS},
   issn = {15737675},
   issue = {1},
   journal = {Journal of Intelligent Information Systems},
   keywords = {Algorithms,Locality sensitive hashing,Real-time recommendation,Recommender systems,Scalability},
   month = {8},
   pages = {1-26},
   publisher = {Springer Science and Business Media, LLC},
   title = {Real-time recommendation with locality sensitive hashing},
   volume = {53},
   url = {https://link.springer.com/article/10.1007/s10844-019-00552-1},
   year = {2019},
}
@article{Koren2009,
   abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest-neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit levels. © 2009, IEEE. All rights reserved.},
   author = {Yehuda Koren and Robert Bell and Chris Volinsky},
   doi = {10.1109/MC.2009.263},
   issn = {00189162},
   issue = {8},
   journal = {Computer},
   pages = {30-37},
   title = {Matrix factorization techniques for recommender systems},
   volume = {42},
   year = {2009},
}
@book{,
   abstract = {Recommender systems are widely used for personalized recommendation in many business applications such as online shopping websites and social network platforms. However, with the tremendous growth of recommendation space (e.g., number of users, products, etc.), traditional systems suffer from time and space complexity issues and cannot make real-time recommendations when dealing with large-scale data. In this paper, we propose an efficient recommender system by incorporating the locality sensitive hashing (LSH) strategy. We show that LSH can approximately preserve similarities of data while significantly reducing data dimensions. We conduct experiments on synthetic and real-world datasets of various sizes and data types. The experiment results show that the proposed LSH-based system generally outperforms traditional item-based collaborative filtering in most cases in terms of statistical accuracy, decision support accuracy, and efficiency. This paper contributes to the fields of recommender systems and big data analytics by proposing a novel recommendation approach that can handle large-scale data efficiently.},
   author = {Kunpeng Zhang and Shaokun Fan and Harry Jiannan Wang},
   isbn = {9780998133119},
   title = {An Efficient Recommender System Using Locality Sensitive Hashing},
   url = {https://www.scrapehero.com/how-many-products-are-},
}
@misc{Resnick1997,
   author = {Paul Resnick and Hal R Varian},
   issue = {3},
   journal = {COMMUNICATIONS OF THE ACM},
   title = {Recommender Systems},
   volume = {40},
   url = {http://www.firefly.com},
   year = {1997},
}
@article{Burke2002,
   author = {Robin Burke},
   doi = {10.1023/A:1021240730564},
   issn = {09241868},
   issue = {4},
   journal = {User Modeling and User-Adapted Interaction},
   pages = {331-370},
   title = {Hybrid Recommender Systems: Survey and Experiments},
   volume = {12},
   year = {2002},
}
@article{Lu2018,
   abstract = {Reinforcement learning methods have been used for learning dialogue policies. However, learning an effective dialogue policy frequently requires prohibitively many conversations. This is partly because of the sparse rewards in dialogues, and the very few successful dialogues in early learning phase. Hindsight experience replay (HER) enables learning from failures, but the vanilla HER is inapplicable to dialogue learning due to the implicit goals. In this work, we develop two complex HER methods providing different trade-offs between complexity and performance, and, for the first time, enabled HER-based dialogue policy learning. Experiments using a realistic user simulator show that our HER methods perform better than existing experience replay methods (as applied to deep Q-networks) in learning rate.},
   author = {Keting Lu and Shiqi Zhang and Xiaoping Chen},
   doi = {10.1609/aaai.v33i01.33012596},
   isbn = {9781577358091},
   issn = {2159-5399},
   journal = {33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019},
   month = {8},
   pages = {2596-2603},
   publisher = {AAAI Press},
   title = {Goal-oriented Dialogue Policy Learning from Failures},
   url = {https://arxiv.org/abs/1808.06497v2},
   year = {2018},
}
@article{Wu2019,
   abstract = {Training task-completion dialogue agents with reinforcement learning usually requires a large number of real user experiences. The Dyna-Q algorithm extends Q-learning by integrating a world model, and thus can effectively boost training efficiency using simulated experiences generated by the world model. The effectiveness of Dyna-Q, however, depends on the quality of the world model - or implicitly, the pre-specified ratio of real vs. simulated experiences used for Q-learning. To this end, we extend the recently proposed Deep Dyna-Q (DDQ) framework by integrating a switcher that automatically determines whether to use a real or simulated experience for Q-learning. Furthermore, we explore the use of active learning for improving sample efficiency, by encouraging the world model to generate simulated experiences in the stateaction space where the agent has not (fully) explored. Our results show that by combining switcher and active learning, the new framework named as Switch-based Active Deep Dyna-Q (Switch-DDQ), leads to significant improvement over DDQ and Q-learning baselines in both simulation and human evaluations.1},
   author = {Yuexin Wu and Xiujun Li and Jingjing Liu and Jianfeng Gao and Yiming Yang},
   doi = {10.1609/AAAI.V33I01.33017289},
   isbn = {9781577358091},
   issn = {2374-3468},
   issue = {01},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   month = {7},
   pages = {7289-7296},
   publisher = {AAAI Press},
   title = {Switch-Based Active Deep Dyna-Q: Efficient Adaptive Planning for Task-Completion Dialogue Policy Learning},
   volume = {33},
   url = {https://ojs.aaai.org/index.php/AAAI/article/view/4715},
   year = {2019},
}
@misc{Peng2018,
   abstract = {Training a task-completion dialogue agent via reinforcement learning (RL) is costly because it requires many interactions with real users. One common alternative is to use a user simulator. However, a user simulator usually lacks the language complexity of human interlocutors and the biases in its design may tend to degrade the agent. To address these issues, we present Deep Dyna-Q, which to our knowledge is the first deep RL framework that integrates planning for task-completion dialogue policy learning. We incorporate into the dialogue agent a model of the environment , referred to as the world model, to mimic real user response and generate simulated experience. During dialogue policy learning, the world model is constantly updated with real user experience to approach real user behavior, and in turn, the dialogue agent is optimized using both real experience and simulated experience. The effectiveness of our approach is demonstrated on a movie-ticket booking task in both simulated and human-in-the-loop settings 1 .},
   author = {Baolin Peng and Xiujun Li and Jianfeng Gao and JJ (Jingjing) Liu and Kam-Fai Wong and Shang-Yu Su},
   month = {1},
   title = {Deep Dyna-Q: Integrating planning for task-completion dialogue policy learning},
   url = {https://www.microsoft.com/en-us/research/publication/integrating-planning-task-completion-dialogue-policy-learning/},
   year = {2018},
}
@article{Wang2021,
   abstract = {Pre-trained models for Natural Languages (NL) like BERT and GPT have been recently shown to transfer well to Programming Languages (PL) and largely benefit a broad set of code-related tasks. Despite their success, most current methods either rely on an encoder-only (or decoder-only) pre-training that is suboptimal for generation (resp. understanding) tasks or process the code snippet in the same way as NL, neglecting the special characteristics of PL such as token types. We present CodeT5, a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. Our model employs a unified framework to seamlessly support both code understanding and generation tasks and allows for multi-task learning. Besides, we propose a novel identifier-aware pre-training task that enables the model to distinguish which code tokens are identifiers and to recover them when they are masked. Furthermore, we propose to exploit the user-written code comments with a bimodal dual generation task for better NL-PL alignment. Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL. Further analysis reveals that our model can better capture semantic information from code. Our code and pre-trained models are released at https: //github.com/salesforce/CodeT5 .},
   author = {Yue Wang and Weishi Wang and Shafiq Joty and Steven C. H. Hoi},
   month = {9},
   title = {CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
   year = {2021},
}
@article{Feng2020,
   abstract = {We present CodeBERT, a bimodal pre-trained model for programming language (PL) and nat-ural language (NL). CodeBERT learns general-purpose representations that support downstream NL-PL applications such as natural language codesearch, code documentation generation, etc. We develop CodeBERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators. This enables us to utilize both bimodal data of NL-PL pairs and unimodal data, where the former provides input tokens for model training while the latter helps to learn better generators. We evaluate CodeBERT on two NL-PL applications by fine-tuning model parameters. Results show that CodeBERT achieves state-of-the-art performance on both natural language code search and code documentation generation tasks. Furthermore, to investigate what type of knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and evaluate in a zero-shot setting where parameters of pre-trained models are fixed. Results show that CodeBERT performs better than previous pre-trained models on NL-PL probing.},
   author = {Zhangyin Feng and Daya Guo and Duyu Tang and Nan Duan and Xiaocheng Feng and Ming Gong and Linjun Shou and Bing Qin and Ting Liu and Daxin Jiang and Ming Zhou},
   month = {2},
   title = {CodeBERT: A Pre-Trained Model for Programming and Natural Languages},
   year = {2020},
}
@article{Xiao2023,
   abstract = {Due to advances in technology, conversational agents are emerging as intelligent spoken dialogue systems that simulate natural conversation with human beings. A growing body of literature has investigated the potential of conversational agents in enhancing language learning across multiple contexts. In this paper, a broad scoping review examining the current literature on conversational agents and language learning was conducted. This review mapped APA PsycINFO, ERIC and ProQuest Dissertations & Theses databases, which yielded 23 papers for further analysis. Our examination of these papers suggests that there are three main ways in which conversational agents are used for language learning. This review discusses these three approaches and points to directions that require further research to fully exploit the potential of conversational agents in language learning.},
   author = {Feiwen Xiao and Priscilla Zhao and Hanyue Sha and Dandan Yang and Mark Warschauer},
   doi = {10.1515/JCCALL-2022-0032},
   issn = {2748-3479},
   issue = {0},
   journal = {Journal of China Computer-Assisted Language Learning},
   keywords = {CALL,conversational agents,language learning,natural language processing (NLP),technology},
   month = {3},
   publisher = {De Gruyter},
   title = {Conversational agents in language learning},
   volume = {0},
   url = {https://www.degruyter.com/document/doi/10.1515/jccall-2022-0032/html},
   year = {2023},
}
@article{Vorvoreanu2019,
   abstract = {In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases-not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared. CCS CONCEPTS • Human-centered computing → Human-Computer Interaction (HCI) → HCI design and evaluation methods},
   author = {Mihaela Vorvoreanu and Lingyi Zhang and Yun-Han Huang and Claudia Hilderbrand and Zoe Steine-Hanson and Margaret Burnett},
   doi = {10.1145/3290605.3300283},
   isbn = {9781450359702},
   keywords = {Gender-inclusive software,GenderMag,gender biases},
   publisher = {ACM},
   title = {From Gender Biases to Gender-Inclusive Design: An Empirical Investigation},
   url = {https://doi.org/10.1145/3290605.3300283},
   year = {2019},
}
@article{,
   abstract = {The Generative Pre-trained Transformer (GPT) represent a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, enabling technologies, their impact on various applications, emerging challenges, and potential solutions.},
   author = {Gokul Yenduri and Chemmalar G Selvi and Gautam Srivastava and Praveen Kumar Reddy Maddikunta and Deepti G Raj and Rutvij H Jhaveri and Weizheng Wang and Athanasios V Vasilakos and Thippa Reddy Gadekallu},
   keywords = {Artificial Intelligence,Index Terms-Generative Pre-trained Transformer,Natural language processing},
   title = {GPT (Generative Pre-trained Transformer)-A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions},
}
@article{,
   abstract = {Recent neural models of dialogue generation offer great promise for generating responses for conversational agents, but tend to be shortsighted , predicting utterances one at a time while ignoring their influence on future outcomes. Modeling the future direction of a dialogue is crucial to generating coherent, interesting dialogues, a need which led traditional NLP models of dialogue to draw on reinforcement learning. In this paper, we show how to integrate these goals, applying deep reinforcement learning to model future reward in chat-bot dialogue. The model simulates dialogues between two virtual agents, using policy gradient methods to reward sequences that display three useful conversational properties: infor-mativity, coherence, and ease of answering (re-lated to forward-looking function). We evaluate our model on diversity, length as well as with human judges, showing that the proposed algorithm generates more interactive responses and manages to foster a more sustained conversation in dialogue simulation. This work marks a first step towards learning a neural conversational model based on the long-term success of dialogues.},
   author = {Jiwei Li and Will Monroe and Alan Ritter and Michel Galley and Jianfeng Gao and Dan Jurafsky},
   pages = {1192-1202},
   title = {Deep Reinforcement Learning for Dialogue Generation},
   url = {https://en.wikipedia.org/wiki/Yes,_and...},
}
@misc{,
   journal = {Wikipedia},
   title = {Artificial Intelligence Act},
   url = {https://en.wikipedia.org/wiki/Artificial_Intelligence_Act},
}
@misc{,
   author = {RAIL Publications},
   title = {Responsible AI Licenses (RAIL)},
   url = {https://www.licenses.ai/},
}
@misc{,
   title = {Responsible AI at Google Research: PAIR – Google Research Blog},
   url = {https://blog.research.google/2023/05/responsible-ai-at-google-research-pair.html},
}
@misc{,
   title = {Everyday ethics for AI},
   url = {https://www.ibm.com/design/ai/ethics/everyday-ethics/},
}
@article{Xu2022,
   author = {Fuyong Xu and Guangtao Xu and Yuanying Wang and Ru Wang and Qi Ding and Peiyu Liu and Zhenfang Zhu},
   doi = {10.1007/s10489-021-02660-4},
   issn = {0924-669X},
   issue = {5},
   journal = {Applied Intelligence},
   month = {3},
   pages = {4744-4757},
   title = {Diverse dialogue generation by fusing mutual persona-aware and self-transferrer},
   volume = {52},
   year = {2022},
}
@article{Xu2023,
   author = {Fuyong Xu and Zhaoxin Ding and Zhenfang Zhu and Peiyu Liu},
   doi = {10.1007/s11227-023-05209-z},
   issn = {0920-8542},
   issue = {13},
   journal = {The Journal of Supercomputing},
   month = {9},
   pages = {14545-14570},
   title = {Exploring implicit persona knowledge for personalized dialogue generation},
   volume = {79},
   year = {2023},
}
@article{Buller1991,
   author = {David B. Buller and Krystyna D. Strzyzewski and Frank G. Hunsaker},
   doi = {10.1080/03637759109376212},
   issn = {0363-7751},
   issue = {1},
   journal = {Communication Monographs},
   month = {3},
   pages = {25-40},
   title = {Interpersonal deception: II. The inferiority of conversational participants as deception detectors},
   volume = {58},
   year = {1991},
}
@article{Hepenstal2019,
   author = {S. Hepenstal and N. Kodagoda and Leishi Zhang and Pragya Paudyal and B. Wong},
   journal = {IUI Workshops},
   title = {Algorithmic Transparency of Conversational Agents},
   year = {2019},
}
@inproceedings{Motta2023,
   author = {Isabela Motta and Manuela Quaresma},
   city = {New York, NY, USA},
   doi = {10.1145/3571884.3604304},
   isbn = {9798400700149},
   journal = {Proceedings of the 5th International Conference on Conversational User Interfaces},
   month = {7},
   pages = {1-4},
   publisher = {ACM},
   title = {Increasing Transparency to Design Inclusive Conversational Agents (CAs): Perspectives and Open Issues},
   year = {2023},
}
@inproceedings{Hendrickx2021,
   author = {Iris Hendrickx and Federica Cena and Erkan Basar and Luigi Di Caro and Florian Kunneman and Elena Musi and Cataldo Musto and Amon Rapp and Jelte van Waterschoot},
   city = {New York, NY, USA},
   doi = {10.1145/3450614.3461453},
   isbn = {9781450383677},
   journal = {Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization},
   month = {6},
   pages = {373-374},
   publisher = {ACM},
   title = {Towards a New generation of Personalized Intelligent Conversational Agents},
   year = {2021},
}
@article{Schuetzler2019,
   author = {Ryan M. Schuetzler and G. Mark Grimes and Justin Scott Giboney},
   doi = {10.1016/j.chb.2019.03.033},
   issn = {07475632},
   journal = {Computers in Human Behavior},
   month = {8},
   pages = {250-259},
   title = {The effect of conversational agent skill on user behavior during deception},
   volume = {97},
   year = {2019},
}
@article{,
   abstract = {Purpose: Conversational agents (chatbots, avatars and robots) are increasingly substituting human employees in service encounters. Their presence offers many potential benefits, but customers are reluctant to engage with them. A possible explanation is that conversational agents do not make optimal use of communicative behaviors that enhance relational outcomes. The purpose of this paper is to identify which human-like communicative behaviors used by conversational agents have positive effects on relational outcomes and which additional behaviors could be investigated in future research. Design/methodology/approach: This paper presents a systematic review of 61 articles that investigated the effects of communicative behaviors used by conversational agents on relational outcomes. A taxonomy is created of all behaviors investigated in these studies, and a research agenda is constructed on the basis of an analysis of their effects and a comparison with the literature on human-to-human service encounters. Findings: The communicative behaviors can be classified along two dimensions: modality (verbal, nonverbal, appearance) and footing (similarity, responsiveness). Regarding the research agenda, it is noteworthy that some categories of behaviors show mixed results and some behaviors that are effective in human-to-human interactions have not yet been investigated in conversational agents. Practical implications: By identifying potentially effective communicative behaviors in conversational agents, this study assists managers in optimizing encounters between conversational agents and customers. Originality/value: This is the first study that develops a taxonomy of communicative behaviors in conversational agents and uses it to identify avenues for future research.},
   author = {Michelle M.E. Van Pinxteren and Mark Pluymaekers and Jos G.A.M. Lemmink},
   doi = {10.1108/JOSM-06-2019-0175/FULL/PDF},
   issn = {17575818},
   issue = {2},
   journal = {Journal of Service Management},
   keywords = {Avatar,Chatbot,Communicative behaviors,Conversational agents,Relational outcomes,Robot},
   month = {9},
   pages = {203-225},
   publisher = {Emerald Group Holdings Ltd.},
   title = {Human-like communication in conversational agents: a literature review and research agenda},
   volume = {31},
   year = {2020},
}
@article{,
   abstract = {Culturally informed design for virtual agents has been shown to positively impact health outcomes when tailored to target audiences. We present a participatory design methodology for culturally tailoring virtual agents. Investigators worked with key informants from our target population, members of predominantly Black church communities, to design culturally-relevant and sensitive virtual agent health promotion interventions. In the first participatory session, key informants designed agents to assist them with different aspects of their lives, providing input on agent appearance and agent functionality. In a second design session, participants re-wrote the content of a health conversation with an agent, to include personally-relevant content related to their community (e.g., religious and scriptural references). We report design principles for religious tailoring derived from these studies. We conducted a validation study to assess the effects of applying these principles to agents that promoted two health behaviors, finding that participants responded very positively to the tailored agents.},
   author = {Teresa K. O'Leary and Elizabeth Stowell and Everlyne Kimani and Dhaval Parmar and Stefan Olafsson and Jessica Hoffman and Andrea G. Parker and Michael K. Paasche-Orlow and Timothy Bickmore},
   doi = {10.1145/3383652.3423875},
   isbn = {9781450375863},
   journal = {Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020},
   keywords = {Cultural tailoring,Embodied conversational agents,Faith-based communities,Health promotion,Participatory design,User study},
   month = {10},
   publisher = {Association for Computing Machinery, Inc},
   title = {Community-Based Cultural Tailoring of Virtual Agents},
   volume = {20},
   url = {https://dl.acm.org/doi/10.1145/3383652.3423875},
   year = {2020},
}
@article{,
   author = {Michelle M.E. Van Pinxteren and Mark Pluymaekers and Jos G.A.M. Lemmink},
   doi = {10.1108/JOSM-06-2019-0175},
   issn = {1757-5818},
   issue = {2},
   journal = {Journal of Service Management},
   month = {6},
   pages = {203-225},
   title = {Human-like communication in conversational agents: a literature review and research agenda},
   volume = {31},
   year = {2020},
}
@article{McDonnell2019,
   author = {Marian McDonnell and David Baxter},
   doi = {10.1093/iwc/iwz007},
   issn = {0953-5438},
   issue = {2},
   journal = {Interacting with Computers},
   month = {3},
   pages = {116-121},
   title = {Chatbots and Gender Stereotyping},
   volume = {31},
   year = {2019},
}
@article{Wang2023,
   abstract = {The recent surge in the research of diffusion models has accelerated the adoption of text-to-image models in various Artificial Intelligence Generated Content (AIGC) commercial products. While these exceptional AIGC products are gaining increasing recognition and sparking enthusiasm among consumers, the questions regarding whether, when, and how these models might unintentionally reinforce existing societal stereotypes remain largely unaddressed. Motivated by recent advancements in language agents, here we introduce a novel agent architecture tailored for stereotype detection in text-to-image models. This versatile agent architecture is capable of accommodating free-form detection tasks and can autonomously invoke various tools to facilitate the entire process, from generating corresponding instructions and images, to detecting stereotypes. We build the stereotype-relevant benchmark based on multiple open-text datasets, and apply this architecture to commercial products and popular open source text-to-image models. We find that these models often display serious stereotypes when it comes to certain prompts about personal characteristics, social cultural context and crime-related aspects. In summary, these empirical findings underscore the pervasive existence of stereotypes across social dimensions, including gender, race, and religion, which not only validate the effectiveness of our proposed approach, but also emphasize the critical necessity of addressing potential ethical risks in the burgeoning realm of AIGC. As AIGC continues its rapid expansion trajectory, with new models and plugins emerging daily in staggering numbers, the challenge lies in the timely detection and mitigation of potential biases within these models.},
   author = {Qichao Wang and Tian Bian and Yian Yin and Tingyang Xu and Hong Cheng and Helen M. Meng and Zibin Zheng and Liang Chen and Bingzhe Wu},
   month = {10},
   title = {Language Agents for Detecting Implicit Stereotypes in Text-to-image Models at Scale},
   year = {2023},
}
@inbook{Rehm2009,
   author = {Matthias Rehm and Elisabeth André and Yukiko Nakano},
   doi = {10.1007/978-3-642-02580-8_37},
   pages = {340-348},
   title = {Some Pitfalls for Developing Enculturated Conversational Agents},
   year = {2009},
}
@article{Dai2019,
   abstract = {Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.},
   author = {Zihang Dai and Zhilin Yang and Yiming Yang and Jaime Carbonell and Quoc V. Le and Ruslan Salakhutdinov},
   month = {1},
   title = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
   year = {2019},
}
@article{Avgustis2021,
   abstract = {This paper explores how callers formulate information enquiries for an artificial conversational agent in a call centre and compares it with the way enquiries are addressed to human operators of the same call centre. It includes 60 call recordings with human operators and 103 call recordings with the artificial conversational agent, transcribed and analysed using the method of Conversation Analysis. We show that people formulate and reformulate their enquiries differently to an artificial agent, even though the goal in both cases is to get an answer to the same enquiry. When talking to the artificial conversational agent, callers produce short enquiries, similar to web searches. When connected to human operators, callers formulate longer enquiries which include many details. By analysing the differences in the way callers formulate their enquiries to robots and human operators, we show what callers expect artificial conversational agents to process. These expectations affect the way the enquiry is formulated and, as a result, operators and artificial agents encounter different types of problems they have to repair to understand the question correctly and find an answer to it. Our findings have interesting implications for Human Computer Interaction both in terms of “robot-recipient design” and “user-recipient design”.},
   author = {Iuliia Avgustis and Aleksandr Shirokov and Netta Iivari},
   doi = {10.1007/978-3-030-85610-6_10/COVER},
   isbn = {9783030856090},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Call centre,Conversation analysis,Conversational agent,Recipient design,Speech interface},
   pages = {155-176},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {“Please Connect Me to a Specialist”: Scrutinising ‘Recipient Design’ in Interaction with an Artificial Conversational Agent},
   volume = {12935 LNCS},
   url = {https://link.springer.com/chapter/10.1007/978-3-030-85610-6_10},
   year = {2021},
}
@misc{,
   author = {Wikipedia},
   title = {Instructional design},
   url = {https://en.wikipedia.org/wiki/Instructional_design},
}
@inbook{Neff2010,
   author = {Michael Neff and Yingying Wang and Rob Abbott and Marilyn Walker},
   doi = {10.1007/978-3-642-15892-6_24},
   pages = {222-235},
   title = {Evaluating the Effect of Gesture and Language on Personality Perception in Conversational Agents},
   year = {2010},
}
@article{Yip2023,
   abstract = {<p> With technological developments, individuals are increasingly able to delegate tasks to autonomous agents that act on their behalf. This may cause individuals to behave more fairly, as involving an agent representative encourages individuals to strategise ahead and therefore adhere to social norms of fairness. Research suggests that an audio smiling agent may further promote fairness as it provides a signal of honesty and trust. What is still unclear is whether presenting a multimodal smiling agent (by using visual and auditory cues) rather than a unimodal smiling agent as normally available commercially (using only an auditory cue e.g., Siri) could amplify the impact of smiles. In the present study, participants ( <italic>N</italic>  = 86) played an ultimatum game either directly with another player (control), through a smiling multimodal and unimodal agent or through a neutral multimodal and unimodal agent. Participants’ task was to offer a number of tickets to the other player from a fixed amount. Results showed that when playing the ultimatum game through a smiling multimodal agent, participants offered more tickets to the other player compared to the control condition and the other agent conditions. Hence, exploiting multisensory perception to enhance an agent’s expression may be key for increasing individuals' pro-social behaviour when interacting through such an agent. </p>},
   author = {Hiu Lam Yip and Karin Petrini},
   doi = {10.1007/s12193-023-00403-y},
   issn = {1783-7677},
   issue = {2},
   journal = {Journal on Multimodal User Interfaces},
   month = {6},
   pages = {65-77},
   title = {Investigating the influence of agent modality and expression on agent-mediated fairness behaviours},
   volume = {17},
   year = {2023},
}
@misc{,
   title = {The value of getting personalization right—or wrong—is multiplying | McKinsey},
   url = {https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/the-value-of-getting-personalization-right-or-wrong-is-multiplying},
}
@article{Wang2022,
   abstract = {Pre-trained models have been shown effective in many code intelligence tasks. These models are pre-trained on large-scale unlabeled corpus and then fine-tuned in downstream tasks. However, as the inputs to pre-training and downstream tasks are in different forms, it is hard to fully explore the knowledge of pre-trained models. Besides, the performance of fine-tuning strongly relies on the amount of downstream data, while in practice, the scenarios with scarce data are common. Recent studies in the natural language processing (NLP) field show that prompt tuning, a new paradigm for tuning, alleviates the above issues and achieves promising results in various NLP tasks. In prompt tuning, the prompts inserted during tuning provide task-specific knowledge, which is especially beneficial for tasks with relatively scarce data. In this paper, we empirically evaluate the usage and effect of prompt tuning in code intelligence tasks. We conduct prompt tuning on popular pre-trained models CodeBERT and CodeT5 and experiment with three code intelligence tasks including defect prediction, code summarization, and code translation. Our experimental results show that prompt tuning consistently outperforms fine-tuning in all three tasks. In addition, prompt tuning shows great potential in low-resource scenarios, e.g., improving the BLEU scores of fine-tuning by more than 26\% on average for code summarization. Our results suggest that instead of fine-tuning, we could adapt prompt tuning for code intelligence tasks to achieve better performance, especially when lacking task-specific data.},
   author = {Chaozheng Wang and Yuanhang Yang and Cuiyun Gao and Yun Peng and Hongyu Zhang and Michael R. Lyu},
   doi = {10.1145/3540250.3549113},
   month = {7},
   title = {No More Fine-Tuning? An Experimental Evaluation of Prompt Tuning in Code Intelligence},
   year = {2022},
}
@inproceedings{Zeng2022,
   author = {Zhengran Zeng and Hanzhuo Tan and Haotian Zhang and Jing Li and Yuqun Zhang and Lingming Zhang},
   city = {New York, NY, USA},
   doi = {10.1145/3533767.3534390},
   isbn = {9781450393799},
   journal = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
   month = {7},
   pages = {39-51},
   publisher = {ACM},
   title = {An extensive study on pre-trained models for program understanding and generation},
   year = {2022},
}
@article{Varshney2019,
   abstract = {The paradigm of pretrained deep learning models has recently emerged in artificial intelligence practice, allowing deployment in numerous societal settings with limited computational resources, but also embedding biases and enabling unintended negative uses. In this paper, we treat pretrained models as objects of study and discuss the ethical impacts of their sociological position. We discuss how pretrained models are developed and compared under the common task framework, but that this may make self-regulation inadequate. Further how pretrained models may have a performative effect on society that exacerbates biases. We then discuss how pretrained models move through actor networks as a kind of computationally immutable mobile, but that users also act as agents of technological change by reinterpreting them via fine-tuning and transfer. We further discuss how users may use pretrained models in malicious ways, drawing a novel connection between the responsible innovation and user-centered innovation literatures. We close by discussing how this sociological understanding of pretrained models can inform AI governance frameworks for fairness, accountability, and transparency.},
   author = {Lav R. Varshney and Nitish Shirish Keskar and Richard Socher},
   month = {9},
   title = {Pretrained AI Models: Performativity, Mobility, and Change},
   year = {2019},
}
@article{Shuster2022,
   abstract = {We present BlenderBot 3, a 175B parameter dialogue model capable of open-domain conversation with access to the internet and a long-term memory, and having been trained on a large number of user defined tasks. We release both the model weights and code, and have also deployed the model on a public web page to interact with organic users. This technical report describes how the model was built (architecture, model and training scheme), and details of its deployment, including safety mechanisms. Human evaluations show its superiority to existing open-domain dialogue agents, including its predecessors (Roller et al., 2021; Komeili et al., 2022). Finally, we detail our plan for continual learning using the data collected from deployment, which will also be publicly released. The goal of this research program is thus to enable the community to study ever-improving responsible agents that learn through interaction.},
   author = {Kurt Shuster and Jing Xu and Mojtaba Komeili and Da Ju and Eric Michael Smith and Stephen Roller and Megan Ung and Moya Chen and Kushal Arora and Joshua Lane and Morteza Behrooz and William Ngan and Spencer Poff and Naman Goyal and Arthur Szlam and Y-Lan Boureau and Melanie Kambadur and Jason Weston},
   month = {8},
   title = {BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage},
   year = {2022},
}
@article{Tang2021,
   abstract = {In this paper we define and investigate the problem of \emph\{persona authentication\}: learning a conversational policy to verify the consistency of persona models. We propose a learning objective and prove (under some mild assumptions) that local density estimators trained under this objective maximize the mutual information between persona information and dialog trajectory. Based on the proposed objective, we develop a method of learning an authentication model that adaptively outputs personalized questions to reveal the underlying persona of its partner throughout the course of multi-turn conversation. Experiments show that our authentication method discovers effective question sequences that generalize to unseen persona profiles.},
   author = {Fengyi Tang and Lifan Zeng and Fei Wang and Jiayu Zhou},
   month = {10},
   title = {Persona Authentication through Generative Dialogue},
   year = {2021},
}
@article{Yang2021,
   abstract = {Pre-trained language models learn informative word representations on a large-scale text corpus through self-supervised learning, which has achieved promising performance in fields of natural language processing (NLP) after fine-tuning. These models, however, suffer from poor robustness and lack of interpretability. We refer to pre-trained language models with knowledge injection as knowledge-enhanced pre-trained language models (KEPLMs). These models demonstrate deep understanding and logical reasoning and introduce interpretability. In this survey, we provide a comprehensive overview of KEPLMs in NLP. We first discuss the advancements in pre-trained language models and knowledge representation learning. Then we systematically categorize existing KEPLMs from three different perspectives. Finally, we outline some potential directions of KEPLMs for future research.},
   author = {Jian Yang and Xinyu Hu and Gang Xiao and Yulong Shen},
   month = {10},
   title = {A Survey of Knowledge Enhanced Pre-trained Models},
   year = {2021},
}
@article{Speer2016,
   abstract = {Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.},
   author = {Robyn Speer and Joshua Chin and Catherine Havasi},
   month = {12},
   title = {ConceptNet 5.5: An Open Multilingual Graph of General Knowledge},
   year = {2016},
}
@inbook{Auer2007,
   author = {Sören Auer and Christian Bizer and Georgi Kobilarov and Jens Lehmann and Richard Cyganiak and Zachary Ives},
   doi = {10.1007/978-3-540-76298-0_52},
   pages = {722-735},
   title = {DBpedia: A Nucleus for a Web of Open Data},
   year = {2007},
}
@misc{,
   abstract = {Sustaining coherent and engaging narratives requires dialogue or storytelling agents to understand how the personas of speakers or listeners ground the narrative.},
   author = {Silin Gao and Beatriz Borges and Soyoung Oh and Deniz Bayazit and Saya Kanno and Hiromi Wakaki and Yuki Mitsufuji and Antoine Bosselut},
   pages = {6569-6591},
   publisher = {Long Papers},
   title = {PEACOK: Persona Commonsense Knowledge for Consistent and Engaging Narratives},
   volume = {1},
}
@article{Ghanem2023,
   abstract = {The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness of the responses provided by a conversational agent. While generating answers during conversations consists in generating text from these KGs, it is still regarded as a challenging task that has gained significant attention in recent years. In this document, we provide a review of different architectures used for knowledge graph-to-text generation including: Graph Neural Networks, the Graph Transformer, and linearization with seq2seq models. We discuss the advantages and limitations of each architecture and conclude that the choice of architecture will depend on the specific requirements of the task at hand. We also highlight the importance of considering constraints such as execution time and model validity, particularly in the context of conversational agents. Based on these constraints and the availability of labeled data for the domains of DAVI, we choose to use seq2seq Transformer-based models (PLMs) for the Knowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of kg-to-text generation on PLMs and to explore the emotional and multilingual dimensions in our future work. Overall, this review provides insights into the different approaches for knowledge graph-to-text generation and outlines future directions for research in this area.},
   author = {Hussam Ghanem and Massinissa Atmani and Christophe Cruz},
   month = {7},
   title = {Knowledge Graph for NLG in the context of conversational agents},
   url = {http://arxiv.org/abs/2307.01548},
   year = {2023},
}
@article{Zhang2019,
   abstract = {Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.},
   author = {Zhengyan Zhang and Xu Han and Zhiyuan Liu and Xin Jiang and Maosong Sun and Qun Liu},
   month = {5},
   title = {ERNIE: Enhanced Language Representation with Informative Entities},
   url = {http://arxiv.org/abs/1905.07129},
   year = {2019},
}
@article{Neff2010,
   abstract = {A significant goal in multi-modal virtual agent research is to determine how to vary expressive qualities of a character so that it is perceived in a desired way. The “Big Five” model of personality offers a potential framework for organizing these expressive variations. In this work, we focus on one parameter in this model – extraversion – and demonstrate how both verbal and non-verbal factors impact its perception. Relevant findings from the psychology literature are summarized. Based on these, an experiment was conducted with a virtual agent that demonstrates how language generation, gesture rate and a set of movement performance parameters can be varied to increase or decrease the perceived extraversion. Each of these factors was shown to be significant. These results offer guidance to agent designers on how best to create specific characters.},
   author = {Michael Neff and Yingying Wang and Rob Abbott and Marilyn Walker},
   isbn = {978-3-642-15892-6},
   journal = {Intelligent virtual agents},
   keywords = {conversational and non-verbal behav-,gesture,personality},
   pages = {222-235},
   title = {Evaluating the Effect of Gesture and Language on Personality Perception in Conversational Agents BT - Intelligent Virtual Agents: 10th International Conference, IVA 2010, Philadelphia, PA, USA, September 20-22, 2010. Proceedings},
   url = {http://dx.doi.org/10.1007/978-3-642-15892-6_24},
   year = {2010},
}
@article{Wang2018,
   abstract = {Social relationships (e.g., friends, couple etc.) form the basis of the social network in our daily life. Automatically interpreting such relationships bears a great potential for the intelligent systems to understand human behavior in depth and to better interact with people at a social level. Human beings interpret the social relationships within a group not only based on the people alone, and the interplay between such social relationships and the contextual information around the people also plays a significant role. However, these additional cues are largely overlooked by the previous studies. We found that the interplay between these two factors can be effectively modeled by a novel structured knowledge graph with proper message propagation and attention. And this structured knowledge can be efficiently integrated into the deep neural network architecture to promote social relationship understanding by an end-to-end trainable Graph Reasoning Model (GRM), in which a propagation mechanism is learned to propagate node message through the graph to explore the interaction between persons of interest and the contextual objects. Meanwhile, a graph attentional mechanism is introduced to explicitly reason about the discriminative objects to promote recognition. Extensive experiments on the public benchmarks demonstrate the superiority of our method over the existing leading competitors.},
   author = {Zhouxia Wang and Tianshui Chen and Jimmy Ren and Weihao Yu and Hui Cheng and Liang Lin},
   month = {7},
   title = {Deep Reasoning with Knowledge Graph for Social Relationship Understanding},
   url = {http://arxiv.org/abs/1807.00504},
   year = {2018},
}
@misc{,
   abstract = {We present a theoretically-motivated design perspective, challenges, and applications of next-generation artificial intelligence (AI) systems. We envision systems with greater capabilities for meaningful human interaction, including socially-adaptive behavior that incorporates personalization and sensitivity to social context and intentionality. Personalized knowledge graphs (KGs) combining generic, common-sense and domain-specific knowledge with both socio-cultural values and norms and individual cognitive models provide a foundation for building humanity-inspired AI systems. AI appears in a variety of information technology systems that impact daily living (https://bit.ly/30RZeKL), from navigation services to warning proactively about health issues and weather via virtual assistants. Key policymaking and government organizations recognize the daily significance of AI-infused technologies in our society. Indeed, the American AI Initiative based on the presidential executive order (https://bit.ly/303p9jD), the European Unionns AI Alliance (https://bit.ly/2CPxIFV), and one of the ten big ideas of the U.S. National Science Foundation (https://bit.ly/3g3M3wL) have all focused on the future of work at the human-technology frontier. To serve our social needs effectively in different areas of life-whether healthcare or work performance, AI assistant systems must incorporate and acknowledge the ethical values and social norms that humans take into account when making decisions and taking actions [1]. Consistent with Newellls [2] knowledge level theoretical framework that informs rational behavior of an AI agent, there is a need for principled intelligent systems that reflect and elucidate explicitly both individual and social values and norms in the AI agentts problem solving approach. Humanity-in-the-loop is therefore the core requirement to design such future systems. We define a humanity-inspired AI system as one that incorporates representation and reasoning ability at the knowledge level spanning individual preference and circumstance to collective cultural norms and values. The use of a humanity-in-the-loop concept as the core design requirement replaces a worn human-in-the-loop conceptualization to account explicitly for the broader socio-cultural perspective in addition to an individual's perspective. Knowledge graphs (KGs) [3] provide the foundation to AI systems for the representation and reasoning capability to address this humanity-in-the-loop design requirement.},
   author = {Hemant Purohit},
   title = {Knowledge Graphs to Empower Humanity-inspired AI Systems Next-generation Intelligent Systems: The Perspective for Designing Humanity-inspired AI Systems},
   url = {https://bit.ly/2CPxIFV},
}
@article{Xu2023,
   abstract = {In recent years, personalized dialogue systems have drawn growing attention as they can serve as a personalized assistant for a specific user. A key feature of personalized dialogue systems is the ability to maintain the consistent personality and contextual expression that matches the user’s individual style and needs. Numerous approaches have been developed for creating personalized dialogue systems. However, most existing approaches depend heavily on explicit persona information, such as predefined persona-defining sentences or key-value persona data. When using predefined explicit user persona knowledge in real-world situations, users need to spend more time crafting clear and descriptive persona information. To address this issue, we introduce IMPACT, a generative-based personalized dialogue model that leverages dialogue history to discover implicit persona knowledge. Both implicit and explicit persona knowledge are equally valuable. IMPACT is designed to discover the user’s personalized expression style within dialogues and generate responses that reflect the consistent style. Achieving dialogue consistency requires modeling the complex relationships between the user’s message, persona, and dialogue history. In addition, we use an unlikelihood training objective to optimize the model and further improve dialogue consistency. We conduct comprehensive experiments on two large datasets, and the results show that our method outperforms all baseline models.},
   author = {Fuyong Xu and Zhaoxin Ding and Zhenfang Zhu and Peiyu Liu},
   doi = {10.1007/S11227-023-05209-Z/METRICS},
   issn = {15730484},
   issue = {13},
   journal = {Journal of Supercomputing},
   keywords = {Dialogue consistency,Implicit persona,Knowledge discovering,Open-domain dialogue systems,Personalized dialogue generation},
   month = {9},
   pages = {14545-14570},
   publisher = {Springer},
   title = {Exploring implicit persona knowledge for personalized dialogue generation},
   volume = {79},
   url = {https://link.springer.com/article/10.1007/s11227-023-05209-z},
   year = {2023},
}
@article{Weizenbaum1983,
   abstract = {ELIZA is a program operating within the MAC time-sharing system of MIT which makes certain kinds of natural language conversation between man and computer possible. Input sentences are analyzed on the basis of decomposition rules which are triggered by key words appearing in the input text. Responses are generated by reassembly rules associated with selected decomposition rules. The fundamental technical problems with which ELIZA is concerned are: (1) the identification of key words, (2) the discovery of minimal context, (3) the choice of appropriate transformations, (4) generation of responses in the absence of key words, and (5) the provision of an editing capability for ELIZA “scripts”. A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper. © 1983, ACM. All rights reserved. © 1983, ACM. All rights reserved.},
   author = {Joseph Weizenbaum},
   doi = {10.1145/357980.357991},
   issn = {15577317},
   issue = {1},
   journal = {Commun ACM},
   month = {1},
   pages = {23-28},
   title = {ELIZA—a computer program for the study of natural language communication between man and machine (reprint)},
   volume = {26},
   year = {1983},
}
@article{Sherstinsky2018,
   abstract = {Because of their effectiveness in broad practical applications, LSTM networks have received a wealth of coverage in scientific journals, technical blogs, and implementation guides. However, in most articles, the inference formulas for the LSTM network and its parent, RNN, are stated axiomatically, while the training formulas are omitted altogether. In addition, the technique of "unrolling" an RNN is routinely presented without justification throughout the literature. The goal of this paper is to explain the essential RNN and LSTM fundamentals in a single document. Drawing from concepts in signal processing, we formally derive the canonical RNN formulation from differential equations. We then propose and prove a precise statement, which yields the RNN unrolling technique. We also review the difficulties with training the standard RNN and address them by transforming the RNN into the "Vanilla LSTM" network through a series of logical arguments. We provide all equations pertaining to the LSTM system together with detailed descriptions of its constituent entities. Albeit unconventional, our choice of notation and the method for presenting the LSTM system emphasizes ease of understanding. As part of the analysis, we identify new opportunities to enrich the LSTM system and incorporate these extensions into the Vanilla LSTM network, producing the most general LSTM variant to date. The target reader has already been exposed to RNNs and LSTM networks through numerous available resources and is open to an alternative pedagogical approach. A Machine Learning practitioner seeking guidance for implementing our new augmented LSTM model in software for experimentation and research will find the insights and derivations in this tutorial valuable as well.},
   author = {Alex Sherstinsky},
   doi = {10.1016/j.physd.2019.132306},
   month = {8},
   title = {Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network},
   year = {2018},
}
@inproceedings{Blanco2013,
   author = {Henry Blanco and Francesco Ricci},
   city = {New York, NY, USA},
   doi = {10.1145/2507157.2507217},
   isbn = {9781450324090},
   journal = {Proceedings of the 7th ACM conference on Recommender systems},
   month = {10},
   pages = {307-310},
   publisher = {ACM},
   title = {Acquiring user profiles from implicit feedback in a conversational recommender system},
   year = {2013},
}
@article{Jiang2022,
   abstract = {Standardized and quantified evaluation of machine behaviors is a crux of understanding LLMs. In this study, we draw inspiration from psychometric studies by leveraging human personality theory as a tool for studying machine behaviors. Originating as a philosophical quest for human behaviors, the study of personality delves into how individuals differ in thinking, feeling, and behaving. Toward building and understanding human-like social machines, we are motivated to ask: Can we assess machine behaviors by leveraging human psychometric tests in a principled and quantitative manner? If so, can we induce a specific personality in LLMs? To answer these questions, we introduce the Machine Personality Inventory (MPI) tool for studying machine behaviors; MPI follows standardized personality tests, built upon the Big Five Personality Factors (Big Five) theory and personality assessment inventories. By systematically evaluating LLMs with MPI, we provide the first piece of evidence demonstrating the efficacy of MPI in studying LLMs behaviors. We further devise a Personality Prompting (P^2) method to induce LLMs with specific personalities in a controllable way, capable of producing diverse and verifiable behaviors. We hope this work sheds light on future studies by adopting personality as the essential indicator for various downstream tasks, and could further motivate research into equally intriguing human-like machine behaviors.},
   author = {Guangyuan Jiang and Manjie Xu and Song-Chun Zhu and Wenjuan Han and Chi Zhang and Yixin Zhu},
   month = {5},
   title = {Evaluating and Inducing Personality in Pre-trained Language Models},
   url = {http://arxiv.org/abs/2206.07550},
   year = {2022},
}
@article{McRorie2012,
   author = {Margaret McRorie and Ian Sneddon and Gary McKeown and Elisabetta Bevacqua and Etienne de Sevin and Catherine Pelachaud},
   doi = {10.1109/T-AFFC.2011.38},
   issn = {1949-3045},
   issue = {3},
   journal = {IEEE Transactions on Affective Computing},
   month = {7},
   pages = {311-322},
   title = {Evaluation of Four Designed Virtual Agent Personalities},
   volume = {3},
   url = {http://ieeexplore.ieee.org/document/6095506/},
   year = {2012},
}
@inproceedings{Ahmad2022,
   author = {Rangina Ahmad and Dominik Siemon and Ulrich Gnewuch and Susanne Robra-Bissantz},
   doi = {10.24251/HICSS.2022.524},
   title = {A Framework of Personality Cues for Conversational Agents},
   year = {2022},
}
@misc{Ferreira2019,
   abstract = {This research proposes a novel framework for Conversational Agents' personality design having the user as the driving force. The framework uses Social Sciences, Conversation Analysis and Computational Psychology to build a robust methodology for Conversational Agents' personality design. We build the model from three sources of data using qualitative and quantitative methods. The model consists of two personas: the user's persona and the agent's persona. The model is based on real-life customer communication channel data. We discuss the results and the potential for improvement.},
   author = {Catia M Ferreira and Sviatlana Hoehn},
   title = {Crafting Conversational Agents' Personality in a User-centric Context},
   year = {2019},
}
@misc{,
   title = {Knowledge graph - Wikipedia},
   url = {https://en.wikipedia.org/wiki/Knowledge_graph},
}
@misc{Longlivetheux2015,
   author = {Longlivetheux},
   journal = {Wikimedia Commons},
   month = {1},
   title = {DIKW pyramid: data, information, knowledge, and wisdom},
   year = {2015},
}
@article{Roller2020,
   abstract = {Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, and displaying knowledge, empathy and personality appropriately, while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.},
   author = {Stephen Roller and Emily Dinan and Naman Goyal and Da Ju and Mary Williamson and Yinhan Liu and Jing Xu and Myle Ott and Kurt Shuster and Eric M. Smith and Y-Lan Boureau and Jason Weston},
   month = {4},
   title = {Recipes for building an open-domain chatbot},
   year = {2020},
}
@misc{,
   author = {Soshnikov Dmitry and Microsoft},
   journal = {AI-For-Beginners},
   title = {Knowledge Representation and Expert Systems},
   url = {https://github.com/microsoft/AI-For-Beginners},
   year = {2022},
}
@article{Bao2020,
   abstract = {To build a high-quality open-domain chatbot, we introduce the effective training process of PLATO-2 via curriculum learning. There are two stages involved in the learning process. In the first stage, a coarse-grained generation model is trained to learn response generation under the simplified framework of one-to-one mapping. In the second stage, a fine-grained generative model augmented with latent variables and an evaluation model are further trained to generate diverse responses and to select the best response, respectively. PLATO-2 was trained on both Chinese and English data, whose effectiveness and superiority are verified through comprehensive evaluations, achieving new state-of-the-art results.},
   author = {Siqi Bao and Huang He and Fan Wang and Hua Wu and Haifeng Wang and Wenquan Wu and Zhen Guo and Zhibin Liu and Xinchao Xu},
   month = {6},
   title = {PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning},
   year = {2020},
}
@article{Zhang2019,
   abstract = {We present a large, tunable neural conversational response generation model, DialoGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent open-domain dialogue systems.},
   author = {Yizhe Zhang and Siqi Sun and Michel Galley and Yen-Chun Chen and Chris Brockett and Xiang Gao and Jianfeng Gao and Jingjing Liu and Bill Dolan},
   month = {11},
   title = {DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation},
   year = {2019},
}
@article{Wang2021,
   abstract = {In this paper, we describe approaches for developing Emily, an emotion-affective open-domain chatbot. Emily can perceive a user's negative emotion state and offer supports by positively converting the user's emotion states. This is done by finetuning a pretrained dialogue model upon data capturing dialogue contexts and desirable emotion states transition across turns. Emily can differentiate a general open-domain dialogue utterance with questions relating to personal information. By leveraging a question-answering approach based on knowledge graphs to handle personal information, Emily maintains personality consistency. We evaluate Emily against a few state-of-the-art open-domain chatbots and show the effects of the proposed approaches in emotion affecting and addressing personality inconsistency.},
   author = {Weixuan Wang and Xiaoling Cai and Chong Hsuan Huang and Haoran Wang and Haonan Lu and Ximing Liu and Wei Peng},
   month = {9},
   title = {Emily: Developing An Emotion-affective Open-Domain Chatbot with Knowledge Graph-based Persona},
   url = {http://arxiv.org/abs/2109.08875},
   year = {2021},
}
@article{OpenAI2023,
   abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
   author = {OpenAI},
   month = {3},
   title = {GPT-4 Technical Report},
   url = {http://arxiv.org/abs/2303.08774},
   year = {2023},
}
@article{Devlin2018,
   abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
   author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
   month = {10},
   title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
   url = {http://arxiv.org/abs/1810.04805},
   year = {2018},
}
@article{Kingma2013,
   abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
   author = {Diederik P Kingma and Max Welling},
   month = {12},
   title = {Auto-Encoding Variational Bayes},
   url = {http://arxiv.org/abs/1312.6114},
   year = {2013},
}
@misc{,
   abstract = {Chitchat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chitchat more engaging by conditioning on profile information. We collect data and train models to (i) condition on their given profile information ; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown, our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors .},
   author = {Saizheng Zhang and Emily Dinan and Jack Urbanek and Arthur Szlam and Douwe Kiela and Jason Weston},
   pages = {2204-2213},
   publisher = {Association for Computational Linguistics},
   title = {Personalizing Dialogue Agents: I have a dog, do you have pets too?},
   url = {https://github.com/facebookresearch/},
}
@inproceedings{Pradhan2021,
   abstract = {Conversational agents designed to interact through natural language are often imbued with human-like personalities. At times, the agent might also have a distinct persona with traits such as gender, age, or a backstory. Designing such personality or persona for conversational agents has become a common design practice. In this work, we review the emerging literature on designing agent persona or personality, and reflect on these approaches, along with the personas that are created for common conversational agents. We discuss open questions with regards to three aspects: meeting user needs, the ethics of deception, and reinforcing social stereotypes through conversational agents. We hope this work can provoke researchers and practitioners to critically reflect on their approach for designing personality or persona of conversational agents.},
   author = {Alisha Pradhan and Amanda Lazar},
   doi = {10.1145/3469595.3469607},
   isbn = {9781450389983},
   journal = {ACM International Conference Proceeding Series},
   keywords = {Conversational agents,persona,personality,voice assistants},
   month = {7},
   publisher = {Association for Computing Machinery},
   title = {Hey Google, Do You Have a Personality? Designing Personality and Personas for Conversational Agents},
   year = {2021},
}
@article{,
   author = {EQUALS Skills Coalition authorCorporate:UNESCO},
   doi = {10.54675/RAPC9356},
   keywords = {Computer literacy,Digital divide,Gender equality,Gender stereotypes,Information technology,Skills development,Womens participation},
   month = {1},
   title = {I'd blush if I could: closing gender divides in digital skills through education},
   url = {https://unesdoc.unesco.org/ark:/48223/pf0000367416.page=1},
   year = {2019},
}
@misc{,
   title = {Google Gave Google Assistant a Weirdly Specific Backstory},
   url = {https://www.businessinsider.com/google-gave-google-assistant-a-weirdly-specific-backstory-2018-10?r=US&IR=T},
}
@article{Zhou2020,
   abstract = {This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast human– machine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.},
   author = {Li Zhou and Jianfeng Gao and Di Li and Heung Yeung Shum},
   doi = {10.1162/COLI_A_00368},
   issn = {0891-2017},
   issue = {1},
   journal = {Computational Linguistics},
   month = {3},
   pages = {53-93},
   publisher = {MIT Press},
   title = {The Design and Implementation of XiaoIce, an Empathetic Social
                    Chatbot},
   volume = {46},
   url = {https://dx.doi.org/10.1162/coli_a_00368},
   year = {2020},
}
@article{Danielescu2018,
   abstract = {Conversational agents are becoming more common, influenced by the success of Siri and Alexa. As such, new methods and associated challenges of designing for conversational systems are emerging. One factor, unique to conversational agents, that we need to account for as designers, is personality. People attribute personalities to conversational agents, strongly influenced by social expectations, whether or not a particular personality was designed deliberately. In the case of multi-lingual agents, this creates additional challenges: direct translations don’t accommodate cultural variation. We discuss the design process and lessons learned from Radar Pace, a conversational coach that launched with support for five languages. We highlight successes and failures based on user study results and propose changes to the design process to avoid pitfalls for future agents.},
   author = {Andreea Danielescu and Gwen Christian},
   doi = {10.1145/3170427.3174366},
   isbn = {9781450356206},
   journal = {Conference on Human Factors in Computing Systems - Proceedings},
   keywords = {Conversational systems,Interaction design,Personality,Voice user interface design},
   month = {4},
   publisher = {Association for Computing Machinery},
   title = {A bot is not a polyglot: Designing personalities for multi-lingual conversational agents},
   volume = {2018-April},
   url = {https://dl.acm.org/doi/10.1145/3170427.3174366},
   year = {2018},
}
@inproceedings{Kim2019,
   abstract = {Recent years have seen numerous attempts to imbue conversational agents with marked identities by crafting their personalities. However, the question remains as to how such personalities can be systematically designed. To address this problem, this paper proposes a conceptual framework for designing and communicating agent personalities. We conducted two design workshops with 12 designers, discovering three dimensions of an agent personality and three channels to express it. The study results revealed that an agent personality can be crafted by designing common traits shared within a service domain, distinctive traits added for a unique identity, and neutral traits left intentionally undecided or user-driven. Also, such a personality can be expressed through how an agent performs services, what contents it provides, and how it speaks and appears to be. Our results suggest a renewed view of the dimensions of conversational agent personalities.},
   author = {Hankyung Kim and Gaeun Lee and Youn Kyung Lim and Dong Yoon Koh and Jung Mi Park},
   doi = {10.1145/3290607.3312887},
   isbn = {9781450359719},
   journal = {Conference on Human Factors in Computing Systems - Proceedings},
   keywords = {Conversational Agent,Interaction Design,Personality,Voice User interface},
   month = {5},
   publisher = {Association for Computing Machinery},
   title = {Designing personalities of conversational agents},
   year = {2019},
}
@misc{,
   abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs. * Equal contribution, corresponding authors: \{tscialom, htouvron\}@meta.com † Second author Contributions for all the authors can be found in Section A.1.},
   author = {Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael and Smith Ranjan and Subramanian Xiaoqing and Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
   title = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
}
@article{Vaswani2017,
   abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
   author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
   month = {6},
   title = {Attention Is All You Need},
   url = {http://arxiv.org/abs/1706.03762},
   year = {2017},
}
@misc{,
   abstract = {Reinforcement learning methods have been used to compute dialog policies from language-based interaction experiences. Efficiency is of particular importance in dialog policy learning, because of the considerable cost of interacting with people, and the very poor user experience from low-quality conversations. Aiming at improving the efficiency of dialog policy learning, we develop algorithm LHUA (Learning with Hindsight, User modeling, and Adaptation) that, for the first time, enables dialog agents to adaptively learn with hindsight from both simulated and real users. Simulation and hindsight provide the dialog agent with more experience and more (positive) reinforcements respectively. Experimental results suggest that, in success rate and policy quality, LHUA outperforms competitive baselines from the literature, as well as its no-simulation, no-adaptation, and no-hindsight counterparts.},
   author = {Yan Cao and Keting Lu and Xiaoping Chen and Shiqi Zhang},
   pages = {1},
   title = {Adaptive Dialog Policy Learning with Hindsight and User Modeling},
}
@article{Chen2023,
   abstract = {In recent years, the popular Transformer architecture has achieved great success in many application areas, including natural language processing and computer vision. Many existing works aim to reduce the computational and memory complexity of the self-attention mechanism in the Transformer by trading off performance. However, performance is key for the continuing success of the Transformer. In this paper, a family of drop-in replacements for the self-attention mechanism in the Transformer, called the Extractors, is proposed. Four types of the Extractors, namely the super high-performance Extractor (SHE), the higher-performance Extractor (HE), the worthwhile Extractor (WE), and the minimalist Extractor (ME), are proposed as examples. Experimental results show that replacing the self-attention mechanism with the SHE evidently improves the performance of the Transformer, whereas the simplified versions of the SHE, i.e., the HE, the WE, and the ME, perform close to or better than the self-attention mechanism with less computational and memory complexity. Furthermore, the proposed Extractors have the potential or are able to run faster than the self-attention mechanism since their critical paths of computation are much shorter. Additionally, the sequence prediction problem in the context of text generation is formulated using variable-length discrete-time Markov chains, and the Transformer is reviewed based on our understanding.},
   author = {Zhe Chen},
   month = {8},
   title = {Attention Is Not All You Need Anymore},
   url = {http://arxiv.org/abs/2308.07661},
   year = {2023},
}
@article{Wang2022,
   abstract = {A significant goal in an open-domain dialogue system is to make chatbots generate more persona coherent responses given a context. To achieve this goal, some researchers attempt to introduce persona information into neural dialogue models. However, these neural dialogue models describe excessively persona traits during the conversation, which still suffer from the problem of generating boring and meaningful responses. In this paper, we divide the open-domain personalized dialogue generation task into two processes, persona recognition and persona fusion. In the persona recognition process, we use the pre-training model to encode the personas and conversation history independently, which is beneficial to the persona information fusion. Then, we design a dynamic persona fusion mechanism to effectively mine the relevance of dialogue context and persona information, and dynamically predict whether to incorporate persona features in the process of the dialogues. Our model outperforms with 1.23% in Acc., 0.36% in BLEU, 0.92% in F1, and 0.036% in Distinct than baseline models. The experimental results on the ConvAI2 dataset illustrate that the proposed model is superior to baseline approaches for generating more coherent and persona consistent responses.},
   author = {Yuanying Wang and Fuyong Xu and Ru Wang and Zhenfang Zhu and Peiyu Liu and Ran Lu},
   doi = {10.1109/ICPR56361.2022.9956081},
   isbn = {9781665490627},
   issn = {10514651},
   journal = {Proceedings - International Conference on Pattern Recognition},
   pages = {1915-1921},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Improving Persona Understanding for Persona-based Dialogue Generation with Diverse Knowledge Selection},
   volume = {2022-August},
   year = {2022},
}
@article{Ma2021,
   abstract = {Personalized chatbots focus on endowing chatbots with a consistent personality to behave like real users, give more informative responses, and further act as personal assistants. Existing personalized approaches tried to incorporate several text descriptions as explicit user profiles. However, the acquisition of such explicit profiles is expensive and time-consuming, thus being impractical for large-scale real-world applications. Moreover, the restricted predefined profile neglects the language behavior of a real user and cannot be automatically updated together with the change of user interests. In this paper, we propose to learn implicit user profiles automatically from large-scale user dialogue history for building personalized chatbots. Specifically, leveraging the benefits of Transformer on language understanding, we train a personalized language model to construct a general user profile from the user's historical responses. To highlight the relevant historical responses to the input post, we further establish a key-value memory network of historical post-response pairs, and build a dynamic post-aware user profile. The dynamic profile mainly describes what and how the user has responded to similar posts in history. To explicitly utilize users' frequently used words, we design a personalized decoder to fuse two decoding strategies, including generating a word from the generic vocabulary and copying one word from the user's personalized vocabulary. Experiments on two real-world datasets show the significant improvement of our model compared with existing methods. Our code is available at https://github.com/zhengyima/DHAP},
   author = {Zhengyi Ma and Zhicheng Dou and Yutao Zhu and Hanxun Zhong and Ji-Rong Wen},
   doi = {10.1145/3404835.3462828},
   journal = {SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   keywords = {implicit user profile,personalized chatbots,response generation},
   month = {8},
   pages = {555-564},
   publisher = {Association for Computing Machinery, Inc},
   title = {One Chatbot Per Person: Creating Personalized Chatbots based on Implicit User Profiles},
   url = {http://arxiv.org/abs/2108.09355 http://dx.doi.org/10.1145/3404835.3462828},
   year = {2021},
}
@article{An2021,
   abstract = {While interest in AI conversational agents has grown rapidly in recent years, creating agents capable of holding recipient-specific conversations remains a challenge. In other words, an automated agent should be able to engage in recipient design or tailoring the form of its utterances and selection of utterances based on the user's knowledge, or assumptions about what the user knows. Without recipient design, the agent formulates its utterances the same way for every user. While an agent might still fall back on conversational repair practices, such as paraphrase or definition requests, recipient design can minimize the necessity for repair in the first place. In this work, we leverage recipient design methods from natural conversation, as identified in the field of Conversation Analysis (CA) and implement three of them (self-reports of knowledge, prior difficulty in understanding, and prior exposure to a reference) as part of our conversational agent, the Alma Assistant.},
   author = {Sungeun An and Robert Moore and Eric Young Liu and Guang Jie Ren},
   doi = {10.1145/3469595.3469625},
   isbn = {9781450389983},
   journal = {ACM International Conference Proceeding Series},
   keywords = {Conversational UX,Conversational agents,Conversational analysis,Personalization,Recipient design},
   month = {7},
   publisher = {Association for Computing Machinery},
   title = {Recipient Design for Conversational Agents: Tailoring Agent's Utterance to User's Knowledge},
   url = {https://dl.acm.org/doi/10.1145/3469595.3469625},
   year = {2021},
}
@article{Lessio2020,
   abstract = {Conversational agents (CAs), often referred to as chatbots, are being widely deployed within existing commercial frameworks and online service websites. As society moves further into incorporating data rich systems, like the internet of things (IoT), into daily life, it is expected that conversational agents will take on an increasingly important role to help users manage these complex systems. In this, the concept of personality is becoming increasingly important, as we seek for more human-friendly ways to interact with these CAs. In this work a conceptual framework is proposed that considers how existing standard psychological and persona models could be mapped to different kinds of CA functionality outside of strictly dialogue. As CAs become more diverse in their abilities, and more integrated with different kinds of systems, it is important to consider how function can be impacted by the design of agent personality, whether intentionally designed or not. Based on this framework, derived archetype classes of CAs are presented as starting points that can hopefully aid designers, developers, and the curious, into thinking about how to work toward better CA personality development.},
   author = {Nadine Lessio and Alexis Morris},
   doi = {10.1109/SMC42975.2020.9283254},
   isbn = {9781728185262},
   issn = {1062922X},
   journal = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
   keywords = {Archetypes,Conversational Agents,Human-Like Agents,Personality},
   month = {10},
   pages = {3221-3228},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Toward Design Archetypes for Conversational Agent Personality},
   volume = {2020-October},
   year = {2020},
}
@book{Sonlu2021,
   abstract = {Consistently exhibited personalities are crucial elements of realistic, engaging, and behavior-rich conversational virtual agents. Both nonverbal and verbal cues help convey these agents’ unseen ps...},
   author = {Sinan Sonlu and Uǧur Güdükbay and Funda Durupinar},
   doi = {10.1145/3439795},
   issn = {15577368},
   issue = {1},
   journal = {ACM Transactions on Graphics (TOG)},
   keywords = {Conversational agent,Laban movement analysis,OCEAN personality,emotion,nonverbal cues},
   month = {1},
   publisher = {ACM PUB27 New York, NY, USA},
   title = {A Conversational Agent Framework with Multi-modal Personality Expression},
   volume = {40},
   url = {https://dl.acm.org/doi/10.1145/3439795},
   year = {2021},
}
@article{Jeong2019,
   abstract = {Through technological advancements in various areas of our lives, Conversational Agents progressed in their human-likeness. In the field of HCI, however, the use of conversational fillers (e.g., “um,” “uh,” etc.) by Conversational Agents have not been fully explored in an experimental setting. We observed the effects on user perceptions of Intelligence, Human-likeness and Likability of Conversational Agents by a 2 x 2 experimental design. From the results of 26 total participants, we concluded that 1) the use of fillers by Conversational Agents are perceived as less intelligent and less likable in task-oriented conversations, 2) and the fillers did not have any statistically significant change in perception of human-likeness. However, further examination showed that users reported filler-speaking agents as more entertaining for social-oriented conversations. With these findings, we discuss design implications for voice-based Conversational Agents.},
   author = {Yuin Jeong and Younah Kang and Juho Lee},
   doi = {10.1145/3290607.3312913},
   isbn = {9781450359719},
   journal = {Conference on Human Factors in Computing Systems - Proceedings},
   keywords = {Conversational Agent,Conversational Fillers,Human-likeness,Likability,Perceived Intelligence,User Perception,Voice User Interface},
   month = {5},
   publisher = {Association for Computing Machinery},
   title = {Exploring effects of conversational fillers on user perception of conversational agents},
   url = {https://dl.acm.org/doi/10.1145/3290607.3312913},
   year = {2019},
}
